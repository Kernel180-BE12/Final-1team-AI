# import os
# import json
# import re
# from typing import TypedDict, List, Optional
# from flask import Blueprint, request, jsonify, current_app
# from flask_cors import cross_origin
# import sys

# # í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
# project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
# sys.path.insert(0, project_root)

# # Pydantic ë° LangChain í˜¸í™˜ì„±ì„ ìœ„í•œ ì„í¬íŠ¸
# from pydantic import BaseModel, Field, PrivateAttr

# # LangChain ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# from langchain_openai import ChatOpenAI, OpenAIEmbeddings
# from langchain_community.document_loaders.base import BaseLoader
# from langchain.text_splitter import RecursiveCharacterTextSplitter
# from langchain_community.vectorstores import Chroma
# from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever
# from langchain_community.retrievers import BM25Retriever
# from langchain_core.documents import Document
# from langchain_core.prompts import ChatPromptTemplate
# from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
# from langgraph.graph import StateGraph, END

# # FlashRank ì„í¬íŠ¸
# try:
#     from flashrank import Ranker, RerankRequest
#     from langchain.retrievers.document_compressors.base import BaseDocumentCompressor
#     from langchain_core.callbacks.manager import Callbacks
# except ImportError:
#     print("FlashRank ë˜ëŠ” ê´€ë ¨ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#     BaseDocumentCompressor = object
#     Ranker = None

# chatbot_bp = Blueprint('chatbot', __name__)

# # ìƒìˆ˜ ì •ì˜
# MAX_CORRECTION_ATTEMPTS = 5

# class CustomRuleLoader(BaseLoader):
#     def __init__(self, file_path: str, encoding: str = 'utf-8'):
#         self.file_path = file_path
#         self.encoding = encoding
    
#     def load(self) -> List[Document]:
#         docs = []
#         try:
#             with open(self.file_path, 'r', encoding=self.encoding) as f:
#                 content = f.read()
#         except FileNotFoundError:
#             print(f"ğŸš¨ ê²½ê³ : '{self.file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
#             return []
        
#         rule_blocks = re.findall(r'\[ê·œì¹™ ì‹œì‘\](.*?)\[ê·œì¹™ ë\]', content, re.DOTALL)
#         for block in rule_blocks:
#             lines = block.strip().split('\n')
#             metadata = {}
#             page_content = ""
#             is_content_section = False
            
#             for line in lines:
#                 if line.lower().startswith('content:'):
#                     is_content_section = True
#                     page_content += line[len('content:'):].strip() + "\n"
#                     continue
#                 if is_content_section:
#                     page_content += line.strip() + "\n"
#                 else:
#                     if ':' in line:
#                         key, value = line.split(':', 1)
#                         metadata[key.strip()] = value.strip()
            
#             if page_content:
#                 docs.append(Document(page_content=page_content.strip(), metadata=metadata))
        
#         return docs

# class TemplateAnalysisResult(BaseModel):
#     status: str = Field(description="í…œí”Œë¦¿ì˜ ìµœì¢… ìƒíƒœ")
#     reason: str = Field(description="ìƒì„¸í•œ íŒë‹¨ ì´ìœ ")
#     evidence: Optional[str] = Field(None, description="íŒë‹¨ ê·¼ê±° ê·œì¹™ë“¤ì˜ rule_id")
#     suggestion: Optional[str] = Field(None, description="ê°œì„  ì œì•ˆ")
#     revised_template: Optional[str] = Field(None, description="ìˆ˜ì •ëœ í…œí”Œë¦¿")

# class FlashRankRerank(BaseDocumentCompressor):
#     _ranker: Ranker = PrivateAttr()
#     top_n: int = 3
    
#     def __init__(self, *args, **kwargs):
#         super().__init__(*args, **kwargs)
#         if Ranker:
#             self._ranker = Ranker()
    
#     class Config:
#         arbitrary_types_allowed = True
    
#     def compress_documents(self, documents: List[Document], query: str, callbacks: Callbacks | None = None) -> List[Document]:
#         if not documents or not Ranker:
#             return documents[:self.top_n]
        
#         rerank_request = RerankRequest(
#             query=query,
#             passages=[{"id": i, "text": doc.page_content, "metadata": doc.metadata} for i, doc in enumerate(documents)]
#         )
#         reranked_results = self._ranker.rerank(rerank_request)
        
#         final_docs = []
#         for item in reranked_results[:self.top_n]:
#             doc = documents[item['id']]
#             doc.metadata["relevance_score"] = item['score']
#             final_docs.append(doc)
        
#         return final_docs

# class GraphState(TypedDict):
#     original_request: str
#     user_choice: str
#     selected_style: str
#     template_draft: str
#     validation_result: Optional[TemplateAnalysisResult]
#     correction_attempts: int

# # ì „ì—­ ë³€ìˆ˜ë“¤
# llm = None
# retrievers = {}
# approved_templates = []
# rejected_templates = []

# def load_line_by_line(file_path: str) -> List[str]:
#     try:
#         with open(file_path, 'r', encoding='utf-8') as f:
#             items = [line.strip() for line in f if line.strip()]
#         return items
#     except FileNotFoundError:
#         return []

# def load_by_separator(file_path: str, separator: str = '---') -> List[str]:
#     try:
#         with open(file_path, 'r', encoding='utf-8') as f:
#             content = f.read()
#         items = [section.strip() for section in content.split(separator) if section.strip()]
#         return items
#     except FileNotFoundError:
#         return []

# def initialize_system():
#     global llm, retrievers, approved_templates, rejected_templates
    
#     if llm is not None:
#         return  # ì´ë¯¸ ì´ˆê¸°í™”ë¨
    
#     # LLM ì´ˆê¸°í™”
#     llm = ChatOpenAI(model="gpt-4o", temperature=0.2)
    
#     # ë°ì´í„° ë¡œë“œ
#     data_dir = os.path.join(project_root, 'data')
#     approved_templates = load_line_by_line(os.path.join(data_dir, "approved_templates.txt"))
#     rejected_templates = load_by_separator(os.path.join(data_dir, "rejected_templates.txt"))
    
#     # Retriever ì„¤ì •
#     from chromadb.config import Settings
    
#     docs_compliance = CustomRuleLoader(os.path.join(data_dir, "compliance_rules.txt")).load()
#     docs_generation = CustomRuleLoader(os.path.join(data_dir, "generation_rules.txt")).load()
#     docs_whitelist = [Document(page_content=t) for t in approved_templates]
#     docs_rejected = [Document(page_content=t) for t in rejected_templates]
    
#     embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
#     vector_db_path = os.path.join(project_root, "vector_db")
#     client_settings = Settings(anonymized_telemetry=False)
    
#     def create_db(name, docs):
#         if docs:
#             return Chroma.from_documents(
#                 docs, embeddings, 
#                 collection_name=name, 
#                 persist_directory=vector_db_path, 
#                 client_settings=client_settings
#             )
#         return Chroma(
#             collection_name=name, 
#             embedding_function=embeddings, 
#             persist_directory=vector_db_path, 
#             client_settings=client_settings
#         )
    
#     db_compliance = create_db("compliance_rules", docs_compliance)
#     db_generation = create_db("generation_rules", docs_generation)
#     db_whitelist = create_db("whitelist_templates", docs_whitelist)
#     db_rejected = create_db("rejected_templates", docs_rejected)
    
#     def create_hybrid_retriever(vectorstore, docs):
#         if not docs:
#             return vectorstore.as_retriever(search_kwargs={"k": 5})
        
#         vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
#         keyword_retriever = BM25Retriever.from_documents(docs)
#         keyword_retriever.k = 5
        
#         ensemble_retriever = EnsembleRetriever(
#             retrievers=[vector_retriever, keyword_retriever], 
#             weights=[0.5, 0.5]
#         )
        
#         if Ranker:
#             compressor = FlashRankRerank(top_n=3)
#             return ContextualCompressionRetriever(
#                 base_compressor=compressor, 
#                 base_retriever=ensemble_retriever
#             )
#         return ensemble_retriever
    
#     retrievers['compliance'] = create_hybrid_retriever(db_compliance, docs_compliance)
#     retrievers['generation'] = create_hybrid_retriever(db_generation, docs_generation)
#     retrievers['whitelist'] = create_hybrid_retriever(db_whitelist, docs_whitelist)
#     retrievers['rejected'] = create_hybrid_retriever(db_rejected, docs_rejected)

# @chatbot_bp.route('/chat', methods=['POST'])
# @cross_origin()
# def chat():
#     try:
#         initialize_system()
        
#         data = request.get_json()
#         message = data.get('message', '')
#         session_state = data.get('state', {})
        
#         # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
#         if not session_state:
#             session_state = {
#                 'step': 'initial',
#                 'original_request': '',
#                 'user_choice': '',
#                 'selected_style': '',
#                 'template_draft': '',
#                 'validation_result': None,
#                 'correction_attempts': 0
#             }
        
#         response = process_chat_message(message, session_state)
        
#         return jsonify({
#             'success': True,
#             'response': response['message'],
#             'state': response['state'],
#             'options': response.get('options', []),
#             'template': response.get('template', ''),
#             'step': response['state']['step']
#         })
        
#     except Exception as e:
#         return jsonify({
#             'success': False,
#             'error': str(e)
#         }), 500

# def process_chat_message(message: str, state: dict) -> dict:
#     """ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬"""
    
#     if state['step'] == 'initial':
#         # ì²« ìš”ì²­ ì²˜ë¦¬
#         state['original_request'] = message
#         state['step'] = 'recommend_templates'
        
#         # ìœ ì‚¬ í…œí”Œë¦¿ ê²€ìƒ‰
#         similar_docs = retrievers['whitelist'].invoke(message)
        
#         if not similar_docs:
#             state['step'] = 'select_style'
#             return {
#                 'message': 'ìœ ì‚¬í•œ ê¸°ì¡´ í…œí”Œë¦¿ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ í…œí”Œë¦¿ì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.\n\nì›í•˜ì‹œëŠ” ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”:',
#                 'state': state,
#                 'options': ['ê¸°ë³¸í˜•', 'ì´ë¯¸ì§€í˜•', 'ì•„ì´í…œë¦¬ìŠ¤íŠ¸í˜•']
#             }
        
#         templates = []
#         for i, doc in enumerate(similar_docs[:3]):
#             templates.append(f"í…œí”Œë¦¿ {i+1}:\n{doc.page_content}")
        
#         return {
#             'message': 'ìš”ì²­í•˜ì‹  ë‚´ìš©ê³¼ ìœ ì‚¬í•œ ê¸°ì¡´ í…œí”Œë¦¿ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n' + '\n\n'.join(templates) + '\n\nì´ ì¤‘ì—ì„œ ì‚¬ìš©í•˜ì‹¤ í…œí”Œë¦¿ì„ ì„ íƒí•˜ì‹œê±°ë‚˜, ìƒˆë¡œìš´ í…œí”Œë¦¿ ìƒì„±ì„ ì›í•˜ì‹œë©´ "ì‹ ê·œ ìƒì„±"ì„ ì„ íƒí•´ì£¼ì„¸ìš”.',
#             'state': state,
#             'options': ['í…œí”Œë¦¿ 1', 'í…œí”Œë¦¿ 2', 'í…œí”Œë¦¿ 3', 'ì‹ ê·œ ìƒì„±'],
#             'templates': [doc.page_content for doc in similar_docs[:3]]
#         }
    
#     elif state['step'] == 'recommend_templates':
#         # í…œí”Œë¦¿ ì„ íƒ ì²˜ë¦¬
#         if message in ['í…œí”Œë¦¿ 1', 'í…œí”Œë¦¿ 2', 'í…œí”Œë¦¿ 3']:
#             template_idx = int(message.split()[1]) - 1
#             similar_docs = retrievers['whitelist'].invoke(state['original_request'])
#             state['template_draft'] = similar_docs[template_idx].page_content
#             state['step'] = 'validate'
            
#             # ê²€ì¦ ìˆ˜í–‰
#             validation_result = validate_template(state['template_draft'])
#             state['validation_result'] = validation_result
            
#             if validation_result['status'] == 'accepted':
#                 state['step'] = 'completed'
#                 return {
#                     'message': f'âœ… ì„ íƒí•˜ì‹  í…œí”Œë¦¿ì´ ê·œì •ì„ ì¤€ìˆ˜í•©ë‹ˆë‹¤!\n\nìµœì¢… í…œí”Œë¦¿:\n{state["template_draft"]}',
#                     'state': state,
#                     'template': state['template_draft']
#                 }
#             else:
#                 state['step'] = 'correction'
#                 return {
#                     'message': f'ğŸš¨ ì„ íƒí•˜ì‹  í…œí”Œë¦¿ì— ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në¬¸ì œì : {validation_result["reason"]}\n\nê°œì„  ì œì•ˆ: {validation_result["suggestion"]}\n\nAIê°€ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.',
#                     'state': state
#                 }
        
#         elif message == 'ì‹ ê·œ ìƒì„±':
#             state['step'] = 'select_style'
#             return {
#                 'message': 'ìƒˆë¡œìš´ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤. ì›í•˜ì‹œëŠ” ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”:',
#                 'state': state,
#                 'options': ['ê¸°ë³¸í˜•', 'ì´ë¯¸ì§€í˜•', 'ì•„ì´í…œë¦¬ìŠ¤íŠ¸í˜•']
#             }
    
#     elif state['step'] == 'select_style':
#         # ìŠ¤íƒ€ì¼ ì„ íƒ ì²˜ë¦¬
#         if message in ['ê¸°ë³¸í˜•', 'ì´ë¯¸ì§€í˜•', 'ì•„ì´í…œë¦¬ìŠ¤íŠ¸í˜•']:
#             state['selected_style'] = message
#             state['step'] = 'generate'
            
#             # í…œí”Œë¦¿ ìƒì„±
#             template_draft = generate_template(state['original_request'], state['selected_style'])
#             state['template_draft'] = template_draft
            
#             # ê²€ì¦ ìˆ˜í–‰
#             validation_result = validate_template(template_draft)
#             state['validation_result'] = validation_result
            
#             if validation_result['status'] == 'accepted':
#                 state['step'] = 'completed'
#                 return {
#                     'message': f'âœ… ìƒì„±ëœ í…œí”Œë¦¿ì´ ê·œì •ì„ ì¤€ìˆ˜í•©ë‹ˆë‹¤!\n\nìµœì¢… í…œí”Œë¦¿:\n{template_draft}',
#                     'state': state,
#                     'template': template_draft
#                 }
#             else:
#                 state['step'] = 'correction'
#                 state['correction_attempts'] = 0
#                 return {
#                     'message': f'í…œí”Œë¦¿ì„ ìƒì„±í–ˆì§€ë§Œ ê·œì • ìœ„ë°˜ì´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në¬¸ì œì : {validation_result["reason"]}\n\nê°œì„  ì œì•ˆ: {validation_result["suggestion"]}\n\nAIê°€ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.',
#                     'state': state
#                 }
    
#     elif state['step'] == 'correction':
#         # AI ìë™ ìˆ˜ì • ìˆ˜í–‰
#         if state['correction_attempts'] < MAX_CORRECTION_ATTEMPTS:
#             corrected_template = correct_template(state)
#             state['template_draft'] = corrected_template
#             state['correction_attempts'] += 1
            
#             # ì¬ê²€ì¦
#             validation_result = validate_template(corrected_template)
#             state["validation_result"] = validation_result
            
#             if validation_result["status"] == "accepted":
#                 state["step"] = "completed"
#                 return {
#                     "message": f"âœ… AI ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê·œì •ì„ ì¤€ìˆ˜í•˜ëŠ” í…œí”Œë¦¿ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nìµœì¢… í…œí”Œë¦¿:\n{corrected_template}",
#                     "state": state,
#                     "template": corrected_template
#                 }
#             else:
#                 # AIê°€ ìˆ˜ì •í–ˆì§€ë§Œ ì—¬ì „íˆ ë¬¸ì œê°€ ìˆë‹¤ë©´, ë‹¤ì‹œ correction ìŠ¤í…ìœ¼ë¡œ ëŒì•„ê°€ì„œ ì¬ì‹œë„
#                 return process_chat_message(corrected_template, state) # ì¬ê·€ í˜¸ì¶œë¡œ ìë™ ìˆ˜ì • ë°˜ë³µ
#         else:
#             # ìµœëŒ€ ìˆ˜ì • íšŸìˆ˜ ì´ˆê³¼
#             state['step'] = 'manual_correction'
#             return {
#                 'message': f'AI ìë™ ìˆ˜ì •ì´ {MAX_CORRECTION_ATTEMPTS}íšŒ ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n\ní˜„ì¬ í…œí”Œë¦¿:\n{state["template_draft"]}\n\në§ˆì§€ë§‰ ë¬¸ì œì : {state["validation_result"]["reason"]}\n\nì§ì ‘ ìˆ˜ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ? ìˆ˜ì •í•  ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.',
#                 'state': state,
#                 'options': ['í¬ê¸°í•˜ê¸°']
#             }
    
#     elif state['step'] == 'manual_correction':
#         if message == 'í¬ê¸°í•˜ê¸°':
#             state['step'] = 'initial'
#             return {
#                 'message': 'í…œí”Œë¦¿ ìƒì„±ì„ í¬ê¸°í–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ìš”ì²­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.',
#                 'state': {'step': 'initial'},
#             }
#         else:
#             # ì‚¬ìš©ìê°€ ì§ì ‘ ìˆ˜ì •í•œ í…œí”Œë¦¿
#             state['template_draft'] = message
            
#             # ìµœì¢… ê²€ì¦
#             validation_result = validate_template(message)
#             state['validation_result'] = validation_result
            
#             if validation_result['status'] == 'accepted':
#                 state['step'] = 'completed'
#                 return {
#                     'message': f'âœ… ì‚¬ìš©ì ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê·œì •ì„ ì¤€ìˆ˜í•˜ëŠ” í…œí”Œë¦¿ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nìµœì¢… í…œí”Œë¦¿:\n{message}',
#                     'state': state,
#                     'template': message
#                 }
#             else:
#                 return {
#                     'message': f'ğŸš¨ ìˆ˜ì •í•˜ì‹  í…œí”Œë¦¿ì—ë„ ì—¬ì „íˆ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\n\në¬¸ì œì : {validation_result["reason"]}\n\në‹¤ì‹œ ìˆ˜ì •í•´ì£¼ì‹œê±°ë‚˜ "í¬ê¸°í•˜ê¸°"ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.',
#                     'state': state,
#                     'options': ['í¬ê¸°í•˜ê¸°']
#                 }
    
#     elif state['step'] == 'completed':
#         # ìƒˆë¡œìš´ ìš”ì²­ ì‹œì‘
#         state = {'step': 'initial'}
#         return process_chat_message(message, state)
    
#     return {
#         'message': 'ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” ìš”ì²­ì…ë‹ˆë‹¤.',
#         'state': state
#     }

# def generate_template(request: str, style: str) -> str:
#     """í…œí”Œë¦¿ ìƒì„±"""
#     example_docs = retrievers['whitelist'].invoke(request)
#     examples = "\n\n".join([f"ì˜ˆì‹œ {i+1}:\n{doc.page_content}" for i, doc in enumerate(example_docs)])
    
#     expansion_prompt = ChatPromptTemplate.from_template(
#         """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í•µì‹¬ ì˜ë„ì™€ 'ì„ íƒëœ ìŠ¤íƒ€ì¼'ì„ ë°”íƒ•ìœ¼ë¡œ, ì •ë³´ê°€ í’ë¶€í•œ ì•Œë¦¼í†¡ í…œí”Œë¦¿ ì´ˆì•ˆì„ í™•ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
#         ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì•„ë˜ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ **ì •ë³´ê°€ í™•ì¥ëœ í…œí”Œë¦¿ ì´ˆì•ˆ í•˜ë‚˜ë§Œ**ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ˆì•ˆ ì™¸ì— ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ë¡œ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”.
        
#         # ì§€ì‹œì‚¬í•­
#         1. 'ì‚¬ìš©ì í•µì‹¬ ì˜ë„'ë¥¼ ë°”íƒ•ìœ¼ë¡œ, 'ì„ íƒëœ ìŠ¤íƒ€ì¼'ì— ë§ëŠ” ì™„ì „í•œ í…œí”Œë¦¿ ì´ˆì•ˆì„ ë§Œë“œì„¸ìš”.
#         2. 'ìœ ì‚¬í•œ ì„±ê³µ ì‚¬ë¡€'ë¥¼ ì°¸ê³ í•˜ì—¬, ì–´ë–¤ ì •ë³´(ì˜ˆ: ì§€ì› ëŒ€ìƒ, ì‹ ì²­ ê¸°ê°„ ë“±)ë¥¼ ì¶”ê°€í•´ì•¼ í• ì§€ **ì¶”ë¡ **í•˜ê³ , ì ì ˆí•œ #{{ë³€ìˆ˜}}ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        
#         # ì‚¬ìš©ì í•µì‹¬ ì˜ë„: {original_request}
#         # ì„ íƒëœ ìŠ¤íƒ€ì¼: {style}
#         # ìœ ì‚¬í•œ ì„±ê³µ ì‚¬ë¡€ (ì°¸ê³ ìš©): {examples}
        
#         # í™•ì¥ëœ í…œí”Œë¦¿ ì´ˆì•ˆ (ì˜¤ì§ í…œí”Œë¦¿ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥):"""
#     )
    
#     expansion_chain = expansion_prompt | llm | StrOutputParser()
#     expanded_draft = expansion_chain.invoke({
#         "original_request": request,
#         "style": style,
#         "examples": examples
#     })
    
#     return expanded_draft

# def validate_template(draft: str) -> dict:
#     """í…œí”Œë¦¿ ê²€ì¦"""
#     parser = JsonOutputParser(pydantic_object=TemplateAnalysisResult)
    
#     step_back_chain = ChatPromptTemplate.from_template(
#         "ì´ í…œí”Œë¦¿ì˜ í•µì‹¬ ìŸì ì€ ë¬´ì—‡ì¸ê°€?: {draft}"
#     ) | llm | StrOutputParser()
    
#     step_back_question = step_back_chain.invoke({"draft": draft})
    
#     compliance_docs = retrievers['compliance'].invoke(step_back_question)
#     rules_with_metadata = "\n\n".join([
#         f"ë¬¸ì„œ ë‚´ìš©: {doc.page_content}" 
#         for doc in compliance_docs
#     ])
    
#     rejected_docs = retrievers['rejected'].invoke(draft)
#     rejections = "\n\n".join([doc.page_content for doc in rejected_docs])
    
#     validation_prompt = ChatPromptTemplate.from_template(
#         """ë‹¹ì‹ ì€ ê³¼ê±° íŒë¡€ì™€ ë²•ê·œë¥¼ ê·¼ê±°ë¡œ íŒë‹¨í•˜ëŠ” ë§¤ìš° ê¼¼ê¼¼í•œ ìµœì¢… ì‹¬ì‚¬ê´€ì…ë‹ˆë‹¤.
#         ì£¼ì–´ì§„ JSON í˜•ì‹ì— ë§ì¶°ì„œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

#         # ê²€ìˆ˜ ëŒ€ìƒ í…œí”Œë¦¿: {draft}
#         # ê´€ë ¨ ê·œì • (ë©”íƒ€ë°ì´í„° í¬í•¨): {rules}
#         # ìœ ì‚¬í•œ ê³¼ê±° ë°˜ë ¤ ì‚¬ë¡€ (íŒë¡€): {rejections}

#         # ì§€ì‹œì‚¬í•­
#         1. 'reason' í•„ë“œë¥¼ ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ë‹¨ê³„ ì¶”ë¡  ê³¼ì •ì— ë”°ë¼ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”:
#             a. **ì‚¬ì‹¤ í™•ì¸:** ë¨¼ì €, 'ê²€ìˆ˜ ëŒ€ìƒ í…œí”Œë¦¿'ì— ì–´ë–¤ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê°ê´€ì ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.
#             b. **ê·œì • ì—°ê²°:** ë‹¤ìŒìœ¼ë¡œ, í™•ì¸ëœ ì‚¬ì‹¤ê³¼ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ 'ê´€ë ¨ ê·œì •' ë˜ëŠ” 'ìœ ì‚¬í•œ ê³¼ê±° ë°˜ë ¤ ì‚¬ë¡€'ë¥¼ 1~3ê°œ ì°¾ì•„ ì—°ê²°í•˜ì„¸ìš”.
#             c. **ìµœì¢… ê²°ë¡ :** ë§ˆì§€ë§‰ìœ¼ë¡œ, ìœ„ ì‚¬ì‹¤ê³¼ ê·œì •ì„ ì¢…í•©í•˜ì—¬ ì™œ ì´ í…œí”Œë¦¿ì´ 'accepted' ë˜ëŠ” 'rejected'ì¸ì§€ ëª…í™•í•œ ê²°ë¡ ì„ ë‚´ë¦¬ì„¸ìš”.
#         2. ìœ„ë°˜ ì‚¬í•­ì´ ì—†ë‹¤ë©´ 'status'ë¥¼ 'accepted'ë¡œ ì„¤ì •í•˜ê³ , 'revised_template'ì— ì›ë³¸ ì´ˆì•ˆì„ ê·¸ëŒ€ë¡œ ë„£ìœ¼ì„¸ìš”.
#         3. ìœ„ë°˜ ì‚¬í•­ì´ ìˆë‹¤ë©´ 'status'ë¥¼ 'rejected'ë¡œ ì„¤ì •í•˜ê³ , 'suggestion'ì— êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.

#         # ì¶œë ¥ í˜•ì‹ (JSON):
#         {format_instructions}
#         """
#     )
    
#     validation_chain = validation_prompt | llm | parser
#     result = validation_chain.invoke({
#         "draft": draft,
#         "rules": rules_with_metadata,
#         "rejections": rejections,
#         "format_instructions": parser.get_format_instructions()
#     })
    
#     return result

# def correct_template(state: dict) -> str:
#     """í…œí”Œë¦¿ ìˆ˜ì •"""
#     attempts = state.get('correction_attempts', 0)
    
#     if attempts == 0:
#         instruction = "3. ê´‘ê³ ì„± ë¬¸êµ¬ë¥¼ ì œê±°í•˜ê±°ë‚˜, ì •ë³´ì„± ë‚´ìš©ìœ¼ë¡œ ìˆœí™”í•˜ëŠ” ë“±, ì œì•ˆëœ ë°©í–¥ì— ë§ê²Œ í…œí”Œë¦¿ì„ ìˆ˜ì •í•˜ì„¸ìš”."
#     elif attempts == 1:
#         instruction = "3. **(2ì°¨ ìˆ˜ì •)** ì•„ì§ë„ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” 'ì¿ í°', 'í• ì¸', 'ì´ë²¤íŠ¸', 'íŠ¹ê°€'ì™€ ê°™ì€ ëª…ë°±í•œ ê´‘ê³ ì„± ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."
#     else:
#         instruction = """3. **(ìµœì¢… ìˆ˜ì •: ê´€ì  ì „í™˜)** ì—¬ì „íˆ ê´‘ê³ ì„±ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì´ê²ƒì´ ë§ˆì§€ë§‰ ì‹œë„ì…ë‹ˆë‹¤.
#         - **ê´€ì  ì „í™˜:** ë©”ì‹œì§€ì˜ ì£¼ì²´ë¥¼ 'ìš°ë¦¬(ì‚¬ì—…ì)'ì—ì„œ 'ê³ ê°ë‹˜'ìœ¼ë¡œ ì™„ì „íˆ ë°”ê¾¸ì„¸ìš”.
#         - **ëª©ì  ë³€ê²½:** 'íŒë§¤'ë‚˜ 'ë°©ë¬¸ ìœ ë„'ê°€ ì•„ë‹ˆë¼, 'ê³ ê°ë‹˜ì´ ê³¼ê±°ì— ë™ì˜í•œ ë‚´ìš©ì— ë”°ë¼ ê³ ê°ë‹˜ì˜ ê¶Œë¦¬(í˜œíƒ) ì •ë³´ë¥¼ ì•ˆë‚´'í•˜ëŠ” ê²ƒìœ¼ë¡œ ëª©ì ì„ ì¬ì •ì˜í•˜ì„¸ìš”."""
    
#     correction_prompt_template = """ë‹¹ì‹ ì€ ì§€ì ëœ ë¬¸ì œì ì„ í•´ê²°í•˜ì—¬ ë” ë‚˜ì€ ëŒ€ì•ˆì„ ì œì‹œí•˜ëŠ” ì „ë¬¸ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
#     ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì•„ë˜ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ **ìˆ˜ì •ëœ í…œí”Œë¦¿ ì´ˆì•ˆ í•˜ë‚˜ë§Œ**ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ˆì•ˆ ì™¸ì— ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ë¡œ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”.

#     # ì›ë˜ ì‚¬ìš©ì ìš”ì²­: {original_request}
#     # ì´ì „ì— ì œì•ˆí–ˆë˜ í…œí”Œë¦¿ (ë°˜ë ¤ë¨): {rejected_draft}
#     # ë°˜ë ¤ ì‚¬ìœ  ë° ê°œì„  ì œì•ˆ: {rejection_reason}

#     # ì§€ì‹œì‚¬í•­
#     1. 'ë°˜ë ¤ ì‚¬ìœ  ë° ê°œì„  ì œì•ˆ'ì„ ì™„ë²½í•˜ê²Œ ì´í•´í•˜ê³ , ì§€ì ëœ ëª¨ë“  ë¬¸ì œì ì„ í•´ê²°í•˜ì„¸ìš”.
#     2. 'ì›ë˜ ì‚¬ìš©ì ìš”ì²­'ì˜ í•µì‹¬ ì˜ë„ëŠ” ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
#     {dynamic_instruction}

#     # ìˆ˜ì •ëœ í…œí”Œë¦¿ ì´ˆì•ˆ (ì˜¤ì§ í…œí”Œë¦¿ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥):
#     """
    
#     correction_prompt = ChatPromptTemplate.from_template(correction_prompt_template)
#     correction_prompt = correction_prompt.partial(dynamic_instruction=instruction)
    
#     correction_chain = correction_prompt | llm | StrOutputParser()
    
#     new_draft = correction_chain.invoke({
#         "original_request": state['original_request'],
#         "rejected_draft": state['template_draft'],
#         "rejection_reason": state['validation_result']['reason'] + "\nê°œì„  ì œì•ˆ: " + state['validation_result']['suggestion']
#     })
    
#     return new_draft

# @chatbot_bp.route('/health', methods=['GET'])
# def health():
#     return jsonify({'status': 'healthy'})

import os
import json
import re
from typing import TypedDict, List, Optional, Dict
from flask import Blueprint, request, jsonify, current_app
from flask_cors import cross_origin
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ sys.pathì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(os.path.dirname(__file__)))
sys.path.insert(0, project_root)

# Pydantic ë° LangChain í˜¸í™˜ì„±ì„ ìœ„í•œ ì„í¬íŠ¸
from pydantic import BaseModel, Field, PrivateAttr

# LangChain ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders.base import BaseLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import Chroma
from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langgraph.graph import StateGraph, END

# FlashRank ì„í¬íŠ¸
try:
    from flashrank import Ranker, RerankRequest
    from langchain.retrievers.document_compressors.base import BaseDocumentCompressor
    from langchain_core.callbacks.manager import Callbacks
except ImportError:
    print("FlashRank ë˜ëŠ” ê´€ë ¨ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    BaseDocumentCompressor = object
    Ranker = None

chatbot_bp = Blueprint('chatbot', __name__)

# ìƒìˆ˜ ì •ì˜
MAX_CORRECTION_ATTEMPTS = 3

class CustomRuleLoader(BaseLoader):
    def __init__(self, file_path: str, encoding: str = 'utf-8'):
        self.file_path = file_path
        self.encoding = encoding
    
    def load(self) -> List[Document]:
        docs = []
        try:
            with open(self.file_path, 'r', encoding=self.encoding) as f:
                content = f.read()
        except FileNotFoundError:
            print(f"ğŸš¨ ê²½ê³ : '{self.file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        rule_blocks = re.findall(r'\[ê·œì¹™ ì‹œì‘\](.*?)\[ê·œì¹™ ë\]', content, re.DOTALL)
        for block in rule_blocks:
            lines = block.strip().split('\n')
            metadata = {}
            page_content = ""
            is_content_section = False
            
            for line in lines:
                if line.lower().startswith('content:'):
                    is_content_section = True
                    page_content += line[len('content:'):].strip() + "\n"
                    continue
                if is_content_section:
                    page_content += line.strip() + "\n"
                else:
                    if ':' in line:
                        key, value = line.split(':', 1)
                        metadata[key.strip()] = value.strip()
            
            if page_content:
                docs.append(Document(page_content=page_content.strip(), metadata=metadata))
        
        return docs

class TemplateAnalysisResult(BaseModel):
    status: str = Field(description="í…œí”Œë¦¿ì˜ ìµœì¢… ìƒíƒœ")
    reason: str = Field(description="ìƒì„¸í•œ íŒë‹¨ ì´ìœ ")
    evidence: Optional[str] = Field(None, description="íŒë‹¨ ê·¼ê±° ê·œì¹™ë“¤ì˜ rule_id")
    suggestion: Optional[str] = Field(None, description="ê°œì„  ì œì•ˆ")
    revised_template: Optional[str] = Field(None, description="ìˆ˜ì •ëœ í…œí”Œë¦¿")

class FlashRankRerank(BaseDocumentCompressor):
    _ranker: Ranker = PrivateAttr()
    top_n: int = 3
    
    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        if Ranker:
            self._ranker = Ranker()
    
    class Config:
        arbitrary_types_allowed = True
    
    def compress_documents(self, documents: List[Document], query: str, callbacks: Callbacks | None = None) -> List[Document]:
        if not documents or not Ranker:
            return documents[:self.top_n]
        
        rerank_request = RerankRequest(
            query=query,
            passages=[{"id": i, "text": doc.page_content, "metadata": doc.metadata} for i, doc in enumerate(documents)]
        )
        reranked_results = self._ranker.rerank(rerank_request)
        
        final_docs = []
        for item in reranked_results[:self.top_n]:
            doc = documents[item['id']]
            doc.metadata["relevance_score"] = item['score']
            final_docs.append(doc)
        
        return final_docs

class GraphState(TypedDict):
    original_request: str
    user_choice: str
    selected_style: str
    template_draft: str
    validation_result: Optional[TemplateAnalysisResult]
    correction_attempts: int
    
# --- [ì‹ ê·œ ì¶”ê°€] ë³€ìˆ˜ ì¶”ì¶œì„ ìœ„í•œ Pydantic ëª¨ë¸ ---
class Variable(BaseModel):
    name: str = Field(description="ì¶”ì¶œëœ ë³€ìˆ˜ì˜ í•œê¸€ ì´ë¦„ (ì˜ˆ: ë§¤ì¥ëª…, íì ì¼ì). `#{}`ì— ë“¤ì–´ê°ˆ ë¶€ë¶„ì…ë‹ˆë‹¤.")
    original_value: str = Field(description="ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œëœ ì‹¤ì œ ê°’")
    description: str = Field(description="í•´ë‹¹ ë³€ìˆ˜ì— ëŒ€í•œ ê°„ë‹¨í•œ í•œê¸€ ì„¤ëª… (ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡)")

class ParameterizedResult(BaseModel):
    parameterized_template: str = Field(description="íŠ¹ì • ì •ë³´ê°€ #{ë³€ìˆ˜ëª…}ìœ¼ë¡œ ëŒ€ì²´ëœ ìµœì¢… í…œí”Œë¦¿")
    variables: List[Variable] = Field(description="ì¶”ì¶œëœ ë³€ìˆ˜ë“¤ì˜ ëª©ë¡")


# ì „ì—­ ë³€ìˆ˜ë“¤
llm = None
retrievers = {}
approved_templates = []
rejected_templates = []

# --- [ì‹ ê·œ ì¶”ê°€] HTML ë¯¸ë¦¬ë³´ê¸° ìƒì„± í•¨ìˆ˜ ---
def render_final_template(template_string: str) -> str:
    """ìµœì¢… ìŠ¹ì¸ëœ í…œí”Œë¦¿ ë¬¸ìì—´ì„ ë°›ì•„ ì´ë¯¸ì§€ì™€ ìœ ì‚¬í•œ HTML ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
    
    lines = [line.strip() for line in template_string.strip().split('\n') if line.strip()]
    
    if not lines:
        return "<span>ë¯¸ë¦¬ë³´ê¸°ë¥¼ ìƒì„±í•  í…œí”Œë¦¿ì´ ì—†ìŠµë‹ˆë‹¤.</span>"

    title = lines[0]
    button_text = lines[-1]
    
    body_lines = []
    note_lines = []
    for line in lines[1:-1]:
        if line.startswith('*'):
            note_lines.append(line)
        else:
            body_lines.append(line)
            
    body = "<br>".join(body_lines)
    note = "<br>".join(note_lines)

    body = re.sub(r'(#{\w+})', r'<span class="placeholder">\1</span>', body)

    html_output = f"""
    <div class="template-preview">
        <div class="header">ì•Œë¦¼í†¡ ë„ì°©</div>
        <div class="content">
            <div class="icon">ğŸ“„</div>
            <h2 class="title">{title}</h2>
            <div class="body-text">
                {body}
            </div>
            <div class="note-text">
                {note}
            </div>
            <div class="button-container">
                <span>{button_text}</span>
            </div>
        </div>
    </div>
    <style>
        .template-preview {{
            max-width: 350px; border-radius: 8px; overflow: hidden;
            font-family: 'Malgun Gothic', 'ë§‘ì€ ê³ ë”•', sans-serif;
            border: 1px solid #e0e0e0; margin: 1em 0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.1);
        }}
        .template-preview .header {{
            background-color: #F0CA4F; color: #333; padding: 10px 15px;
            font-weight: bold; font-size: 14px;
        }}
        .template-preview .content {{
            background-color: #E6ECF2; padding: 25px 20px; position: relative;
        }}
        .template-preview .icon {{
            position: absolute; top: 25px; right: 20px; font-size: 36px; opacity: 0.5;
        }}
        .template-preview .title {{
            font-size: 24px; font-weight: bold; margin: 0 0 20px;
            padding-right: 40px; color: #333;
        }}
        .template-preview .body-text {{
            font-size: 15px; line-height: 1.6; color: #555; margin-bottom: 20px;
        }}
        .template-preview .note-text {{
            font-size: 13px; line-height: 1.5; color: #777; margin-bottom: 25px;
        }}
        .template-preview .placeholder {{ color: #007bff; font-weight: bold; }}
        .template-preview .button-container {{
            background-color: #FFFFFF; border: 1px solid #d0d0d0; border-radius: 5px;
            text-align: center; padding: 12px 10px; font-size: 15px;
            font-weight: bold; color: #007bff; cursor: pointer;
        }}
    </style>
    """
    return html_output

# --- [ì‹ ê·œ ì¶”ê°€] ë³€ìˆ˜ ìë™ ì¶”ì¶œ í•¨ìˆ˜ ---
def parameterize_template(template_string: str) -> Dict:
    """ì™„ì„±ëœ í…œí”Œë¦¿ ë¬¸ìì—´ì„ ë°›ì•„ ì£¼ìš” ì •ë³´ë¥¼ ë³€ìˆ˜í™”í•©ë‹ˆë‹¤."""
    parser = JsonOutputParser(pydantic_object=ParameterizedResult)
    prompt = ChatPromptTemplate.from_template(
        """ë‹¹ì‹ ì€ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ê³ ìœ ëª…ì‚¬, ë‚ ì§œ, ì¥ì†Œ, ìˆ«ì ë“± êµ¬ì²´ì ì´ê³  ë°”ë€” ìˆ˜ ìˆëŠ” ì •ë³´ë“¤ì„ ì‹ë³„í•˜ì—¬, ì˜ë¯¸ ìˆëŠ” í•œê¸€ ë³€ìˆ˜ëª…ìœ¼ë¡œ ëŒ€ì²´í•´ì£¼ì„¸ìš”.

        # ì§€ì‹œì‚¬í•­
        1. í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ì •ë³´(ëˆ„ê°€, ì–¸ì œ, ì–´ë””ì„œ, ë¬´ì—‡ì„, ì–´ë–»ê²Œ ë“±)ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
        2. íŒŒì•…ëœ ì •ë³´ë¥¼ `#{{ë³€ìˆ˜ëª…}}` í˜•íƒœë¡œ ëŒ€ì²´í•˜ì—¬ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤. ë³€ìˆ˜ëª…ì€ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        3. ì›ë³¸ ê°’ê³¼ ë³€ìˆ˜ëª…, ê·¸ë¦¬ê³  ê° ë³€ìˆ˜ì— ëŒ€í•œ ì„¤ëª…ì„ í¬í•¨í•˜ëŠ” ë³€ìˆ˜ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
        4. ìµœì¢… ê²°ê³¼ë¥¼ ì§€ì •ëœ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ ì™¸ì˜ ì„¤ëª…ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

        # ì›ë³¸ í…ìŠ¤íŠ¸:
        {original_text}

        # ì¶œë ¥ í˜•ì‹ (JSON):
        {format_instructions}
        """
    )
    chain = prompt | llm | parser
    try:
        result = chain.invoke({
            "original_text": template_string,
            "format_instructions": parser.get_format_instructions(),
        })
        return result
    except Exception as e:
        print(f"Error during parameterization: {e}")
        return {"parameterized_template": template_string, "variables": []}


def load_line_by_line(file_path: str) -> List[str]:
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            items = [line.strip() for line in f if line.strip()]
        return items
    except FileNotFoundError:
        return []

def load_by_separator(file_path: str, separator: str = '---') -> List[str]:
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        items = [section.strip() for section in content.split(separator) if section.strip()]
        return items
    except FileNotFoundError:
        return []

def initialize_system():
    global llm, retrievers, approved_templates, rejected_templates
    
    if llm is not None:
        return  # ì´ë¯¸ ì´ˆê¸°í™”ë¨
    
    # LLM ì´ˆê¸°í™”
    llm = ChatOpenAI(model="gpt-4o", temperature=0.2)
    
    # ë°ì´í„° ë¡œë“œ
    data_dir = os.path.join(project_root, 'data')
    approved_templates = load_line_by_line(os.path.join(data_dir, "approved_templates.txt"))
    rejected_templates = load_by_separator(os.path.join(data_dir, "rejected_templates.txt"))
    
    # Retriever ì„¤ì •
    from chromadb.config import Settings
    
    docs_compliance = CustomRuleLoader(os.path.join(data_dir, "compliance_rules.txt")).load()
    docs_generation = CustomRuleLoader(os.path.join(data_dir, "generation_rules.txt")).load()
    docs_whitelist = [Document(page_content=t) for t in approved_templates]
    docs_rejected = [Document(page_content=t) for t in rejected_templates]
    
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vector_db_path = os.path.join(project_root, "vector_db")
    client_settings = Settings(anonymized_telemetry=False)
    
    def create_db(name, docs):
        if docs:
            return Chroma.from_documents(
                docs, embeddings, 
                collection_name=name, 
                persist_directory=vector_db_path, 
                client_settings=client_settings
            )
        return Chroma(
            collection_name=name, 
            embedding_function=embeddings, 
            persist_directory=vector_db_path, 
            client_settings=client_settings
        )
    
    db_compliance = create_db("compliance_rules", docs_compliance)
    db_generation = create_db("generation_rules", docs_generation)
    db_whitelist = create_db("whitelist_templates", docs_whitelist)
    db_rejected = create_db("rejected_templates", docs_rejected)
    
    def create_hybrid_retriever(vectorstore, docs):
        if not docs:
            return vectorstore.as_retriever(search_kwargs={"k": 5})
        
        vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 5})
        keyword_retriever = BM25Retriever.from_documents(docs)
        keyword_retriever.k = 5
        
        ensemble_retriever = EnsembleRetriever(
            retrievers=[vector_retriever, keyword_retriever], 
            weights=[0.5, 0.5]
        )
        
        if Ranker:
            compressor = FlashRankRerank(top_n=3)
            return ContextualCompressionRetriever(
                base_compressor=compressor, 
                base_retriever=ensemble_retriever
            )
        return ensemble_retriever
    
    retrievers['compliance'] = create_hybrid_retriever(db_compliance, docs_compliance)
    retrievers['generation'] = create_hybrid_retriever(db_generation, docs_generation)
    retrievers['whitelist'] = create_hybrid_retriever(db_whitelist, docs_whitelist)
    retrievers['rejected'] = create_hybrid_retriever(db_rejected, docs_rejected)

@chatbot_bp.route('/chat', methods=['POST'])
@cross_origin()
def chat():
    try:
        initialize_system()
        
        data = request.get_json()
        message = data.get('message', '')
        session_state = data.get('state', {})
        
        # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
        if not session_state:
            session_state = {
                'step': 'initial',
                'original_request': '',
                'user_choice': '',
                'selected_style': '',
                'template_draft': '',
                'validation_result': None,
                'correction_attempts': 0
            }
        
        response = process_chat_message(message, session_state)
        
        return jsonify({
            'success': True,
            'response': response['message'],
            'state': response['state'],
            'options': response.get('options', []),
            'template': response.get('template', ''),
            'html_preview': response.get('html_preview', ''),
            'editable_variables': response.get('editable_variables', {}),
            'step': response['state']['step']
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': str(e)
        }), 500

def process_chat_message(message: str, state: dict) -> dict:
    """ì±„íŒ… ë©”ì‹œì§€ ì²˜ë¦¬"""
    
    if state['step'] == 'initial':
        # ì²« ìš”ì²­ ì²˜ë¦¬
        state['original_request'] = message
        state['step'] = 'recommend_templates'
        
        # ìœ ì‚¬ í…œí”Œë¦¿ ê²€ìƒ‰
        similar_docs = retrievers['whitelist'].invoke(message)
        
        if not similar_docs:
            state['step'] = 'select_style'
            return {
                'message': 'ìœ ì‚¬í•œ ê¸°ì¡´ í…œí”Œë¦¿ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ í…œí”Œë¦¿ì„ ìƒì„±í•˜ê² ìŠµë‹ˆë‹¤.\n\nì›í•˜ì‹œëŠ” ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”:',
                'state': state,
                'options': ['ê¸°ë³¸í˜•', 'ì´ë¯¸ì§€í˜•', 'ì•„ì´í…œë¦¬ìŠ¤íŠ¸í˜•']
            }
        
        templates = []
        for i, doc in enumerate(similar_docs[:3]):
            templates.append(f"í…œí”Œë¦¿ {i+1}:\n{doc.page_content}")
        
        return {
            'message': 'ìš”ì²­í•˜ì‹  ë‚´ìš©ê³¼ ìœ ì‚¬í•œ ê¸°ì¡´ í…œí”Œë¦¿ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤:\n\n' + '\n\n'.join(templates) + '\n\nì´ ì¤‘ì—ì„œ ì‚¬ìš©í•˜ì‹¤ í…œí”Œë¦¿ì„ ì„ íƒí•˜ì‹œê±°ë‚˜, ìƒˆë¡œìš´ í…œí”Œë¦¿ ìƒì„±ì„ ì›í•˜ì‹œë©´ "ì‹ ê·œ ìƒì„±"ì„ ì„ íƒí•´ì£¼ì„¸ìš”.',
            'state': state,
            'options': ['í…œí”Œë¦¿ 1', 'í…œí”Œë¦¿ 2', 'í…œí”Œë¦¿ 3', 'ì‹ ê·œ ìƒì„±'],
            'templates': [doc.page_content for doc in similar_docs[:3]]
        }
    
    elif state['step'] == 'recommend_templates':
        # í…œí”Œë¦¿ ì„ íƒ ì²˜ë¦¬
        if message in ['í…œí”Œë¦¿ 1', 'í…œí”Œë¦¿ 2', 'í…œí”Œë¦¿ 3']:
            template_idx = int(message.split()[1]) - 1
            similar_docs = retrievers['whitelist'].invoke(state['original_request'])
            state['template_draft'] = similar_docs[template_idx].page_content
            state['step'] = 'validate'
            
            # ê²€ì¦ ìˆ˜í–‰
            validation_result = validate_template(state['template_draft'])
            state['validation_result'] = validation_result
            
            if validation_result['status'] == 'accepted':
                state['step'] = 'completed'
                final_template = state["template_draft"]
                html_preview = render_final_template(final_template)
                parameterized_result = parameterize_template(final_template)
                return {
                    'message': f'âœ… ì„ íƒí•˜ì‹  í…œí”Œë¦¿ì´ ê·œì •ì„ ì¤€ìˆ˜í•©ë‹ˆë‹¤!\n\nìµœì¢… í…œí”Œë¦¿:\n{final_template}',
                    'state': state,
                    'template': final_template,
                    'html_preview': html_preview,
                    'editable_variables': parameterized_result
                }
            else:
                state['step'] = 'correction'
                return {
                    'message': f'ğŸš¨ ì„ íƒí•˜ì‹  í…œí”Œë¦¿ì— ë¬¸ì œê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤.\n\në¬¸ì œì : {validation_result["reason"]}\n\nê°œì„  ì œì•ˆ: {validation_result["suggestion"]}\n\nAIê°€ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ê² ìŠµë‹ˆë‹¤.',
                    'state': state
                }
        
        elif message == 'ì‹ ê·œ ìƒì„±':
            state['step'] = 'select_style'
            return {
                'message': 'ìƒˆë¡œìš´ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤. ì›í•˜ì‹œëŠ” ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”:',
                'state': state,
                'options': ['ê¸°ë³¸í˜•', 'ì´ë¯¸ì§€í˜•', 'ì•„ì´í…œë¦¬ìŠ¤íŠ¸í˜•']
            }
    
    elif state['step'] == 'select_style':
        # ìŠ¤íƒ€ì¼ ì„ íƒ ì²˜ë¦¬
        if message in ['ê¸°ë³¸í˜•', 'ì´ë¯¸ì§€í˜•', 'ì•„ì´í…œë¦¬ìŠ¤íŠ¸í˜•']:
            state['selected_style'] = message
            state['step'] = 'generate'
            
            # í…œí”Œë¦¿ ìƒì„±
            template_draft = generate_template(state['original_request'], state['selected_style'])
            state['template_draft'] = template_draft
            
            # ê²€ì¦ ìˆ˜í–‰
            validation_result = validate_template(template_draft)
            state['validation_result'] = validation_result
            
            if validation_result['status'] == 'accepted':
                state['step'] = 'completed'
                final_template = template_draft
                html_preview = render_final_template(final_template)
                parameterized_result = parameterize_template(final_template)
                return {
                    'message': f'âœ… ìƒì„±ëœ í…œí”Œë¦¿ì´ ê·œì •ì„ ì¤€ìˆ˜í•©ë‹ˆë‹¤!\n\nìµœì¢… í…œí”Œë¦¿:\n{final_template}',
                    'state': state,
                    'template': final_template,
                    'html_preview': html_preview,
                    'editable_variables': parameterized_result
                }
            else:
                state['step'] = 'correction'
                state['correction_attempts'] = 0
                return process_chat_message('', state) # ìë™ ìˆ˜ì • ì‹œì‘
    
    elif state['step'] == 'correction':
        # AI ìë™ ìˆ˜ì • ìˆ˜í–‰
        if state['correction_attempts'] < MAX_CORRECTION_ATTEMPTS:
            corrected_template = correct_template(state)
            state['template_draft'] = corrected_template
            state['correction_attempts'] += 1
            
            # ì¬ê²€ì¦
            validation_result = validate_template(corrected_template)
            state["validation_result"] = validation_result
            
            if validation_result["status"] == "accepted":
                state["step"] = "completed"
                final_template = corrected_template
                html_preview = render_final_template(final_template)
                parameterized_result = parameterize_template(final_template)
                return {
                    "message": f"âœ… AI ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê·œì •ì„ ì¤€ìˆ˜í•˜ëŠ” í…œí”Œë¦¿ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nìµœì¢… í…œí”Œë¦¿:\n{final_template}",
                    "state": state,
                    "template": final_template,
                    'html_preview': html_preview,
                    'editable_variables': parameterized_result
                }
            else:
                # ìˆ˜ì • í›„ì—ë„ ì‹¤íŒ¨í•˜ë©´ ì¬ê·€ í˜¸ì¶œë¡œ ìë™ ìˆ˜ì • ë°˜ë³µ
                return process_chat_message(corrected_template, state) 
        else:
            # ìµœëŒ€ ìˆ˜ì • íšŸìˆ˜ ì´ˆê³¼
            state['step'] = 'manual_correction'
            return {
                'message': f'AI ìë™ ìˆ˜ì •ì´ {MAX_CORRECTION_ATTEMPTS}íšŒ ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n\ní˜„ì¬ í…œí”Œë¦¿:\n{state["template_draft"]}\n\në§ˆì§€ë§‰ ë¬¸ì œì : {state["validation_result"]["reason"]}\n\nì§ì ‘ ìˆ˜ì •í•˜ì‹œê² ìŠµë‹ˆê¹Œ? ìˆ˜ì •í•  ë‚´ìš©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.',
                'state': state,
                'options': ['í¬ê¸°í•˜ê¸°']
            }
    
    elif state['step'] == 'manual_correction':
        if message == 'í¬ê¸°í•˜ê¸°':
            state['step'] = 'initial'
            return {
                'message': 'í…œí”Œë¦¿ ìƒì„±ì„ í¬ê¸°í–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ìš”ì²­ì„ ì…ë ¥í•´ì£¼ì„¸ìš”.',
                'state': {'step': 'initial'},
            }
        else:
            # ì‚¬ìš©ìê°€ ì§ì ‘ ìˆ˜ì •í•œ í…œí”Œë¦¿
            state['template_draft'] = message
            
            # ìµœì¢… ê²€ì¦
            validation_result = validate_template(message)
            state['validation_result'] = validation_result
            
            if validation_result['status'] == 'accepted':
                state['step'] = 'completed'
                final_template = message
                html_preview = render_final_template(final_template)
                parameterized_result = parameterize_template(final_template)
                return {
                    'message': f'âœ… ì‚¬ìš©ì ìˆ˜ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ê·œì •ì„ ì¤€ìˆ˜í•˜ëŠ” í…œí”Œë¦¿ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n\nìµœì¢… í…œí”Œë¦¿:\n{final_template}',
                    'state': state,
                    'template': final_template,
                    'html_preview': html_preview,
                    'editable_variables': parameterized_result
                }
            else:
                return {
                    'message': f'ğŸš¨ ìˆ˜ì •í•˜ì‹  í…œí”Œë¦¿ì—ë„ ì—¬ì „íˆ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤.\n\në¬¸ì œì : {validation_result["reason"]}\n\në‹¤ì‹œ ìˆ˜ì •í•´ì£¼ì‹œê±°ë‚˜ "í¬ê¸°í•˜ê¸°"ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.',
                    'state': state,
                    'options': ['í¬ê¸°í•˜ê¸°']
                }
    
    elif state['step'] == 'completed':
        # ìƒˆë¡œìš´ ìš”ì²­ ì‹œì‘
        state = {'step': 'initial'}
        return process_chat_message(message, state)
    
    return {
        'message': 'ì£„ì†¡í•©ë‹ˆë‹¤. ì²˜ë¦¬í•  ìˆ˜ ì—†ëŠ” ìš”ì²­ì…ë‹ˆë‹¤.',
        'state': state
    }

def generate_template(request: str, style: str) -> str:
    """í…œí”Œë¦¿ ìƒì„±"""
    example_docs = retrievers['whitelist'].invoke(request)
    examples = "\n\n".join([f"ì˜ˆì‹œ {i+1}:\n{doc.page_content}" for i, doc in enumerate(example_docs)])
    
    expansion_prompt = ChatPromptTemplate.from_template(
        """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ í•µì‹¬ ì˜ë„ì™€ 'ì„ íƒëœ ìŠ¤íƒ€ì¼'ì„ ë°”íƒ•ìœ¼ë¡œ, ì •ë³´ê°€ í’ë¶€í•œ ì•Œë¦¼í†¡ í…œí”Œë¦¿ ì´ˆì•ˆì„ í™•ì¥í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì•„ë˜ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ **ì •ë³´ê°€ í™•ì¥ëœ í…œí”Œë¦¿ ì´ˆì•ˆ í•˜ë‚˜ë§Œ**ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ˆì•ˆ ì™¸ì— ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ë¡œ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”.
        
        # ì§€ì‹œì‚¬í•­
        1. 'ì‚¬ìš©ì í•µì‹¬ ì˜ë„'ë¥¼ ë°”íƒ•ìœ¼ë¡œ, 'ì„ íƒëœ ìŠ¤íƒ€ì¼'ì— ë§ëŠ” ì™„ì „í•œ í…œí”Œë¦¿ ì´ˆì•ˆì„ ë§Œë“œì„¸ìš”.
        2. 'ìœ ì‚¬í•œ ì„±ê³µ ì‚¬ë¡€'ë¥¼ ì°¸ê³ í•˜ì—¬, ì–´ë–¤ ì •ë³´(ì˜ˆ: ì§€ì› ëŒ€ìƒ, ì‹ ì²­ ê¸°ê°„ ë“±)ë¥¼ ì¶”ê°€í•´ì•¼ í• ì§€ **ì¶”ë¡ **í•˜ê³ , ì ì ˆí•œ #{{ë³€ìˆ˜}}ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
        
        # ì‚¬ìš©ì í•µì‹¬ ì˜ë„: {original_request}
        # ì„ íƒëœ ìŠ¤íƒ€ì¼: {style}
        # ìœ ì‚¬í•œ ì„±ê³µ ì‚¬ë¡€ (ì°¸ê³ ìš©): {examples}
        
        # í™•ì¥ëœ í…œí”Œë¦¿ ì´ˆì•ˆ (ì˜¤ì§ í…œí”Œë¦¿ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥):"""
    )
    
    expansion_chain = expansion_prompt | llm | StrOutputParser()
    expanded_draft = expansion_chain.invoke({
        "original_request": request,
        "style": style,
        "examples": examples
    })
    
    return expanded_draft

def validate_template(draft: str) -> dict:
    """í…œí”Œë¦¿ ê²€ì¦"""
    parser = JsonOutputParser(pydantic_object=TemplateAnalysisResult)
    
    step_back_chain = ChatPromptTemplate.from_template(
        "ì´ í…œí”Œë¦¿ì˜ í•µì‹¬ ìŸì ì€ ë¬´ì—‡ì¸ê°€?: {draft}"
    ) | llm | StrOutputParser()
    
    step_back_question = step_back_chain.invoke({"draft": draft})
    
    compliance_docs = retrievers['compliance'].invoke(step_back_question)
    rules_with_metadata = "\n\n".join([
        f"ë¬¸ì„œ ë‚´ìš©: {doc.page_content}" 
        for doc in compliance_docs
    ])
    
    rejected_docs = retrievers['rejected'].invoke(draft)
    rejections = "\n\n".join([doc.page_content for doc in rejected_docs])
    
    validation_prompt = ChatPromptTemplate.from_template(
        """ë‹¹ì‹ ì€ ê³¼ê±° íŒë¡€ì™€ ë²•ê·œë¥¼ ê·¼ê±°ë¡œ íŒë‹¨í•˜ëŠ” ë§¤ìš° ê¼¼ê¼¼í•œ ìµœì¢… ì‹¬ì‚¬ê´€ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ JSON í˜•ì‹ì— ë§ì¶°ì„œë§Œ ë‹µë³€í•´ì•¼ í•©ë‹ˆë‹¤.

        # ê²€ìˆ˜ ëŒ€ìƒ í…œí”Œë¦¿: {draft}
        # ê´€ë ¨ ê·œì • (ë©”íƒ€ë°ì´í„° í¬í•¨): {rules}
        # ìœ ì‚¬í•œ ê³¼ê±° ë°˜ë ¤ ì‚¬ë¡€ (íŒë¡€): {rejections}

        # ì§€ì‹œì‚¬í•­
        1. 'reason' í•„ë“œë¥¼ ë‹¤ìŒê³¼ ê°™ì€ ë‹¤ë‹¨ê³„ ì¶”ë¡  ê³¼ì •ì— ë”°ë¼ ìƒì„¸í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”:
            a. **ì‚¬ì‹¤ í™•ì¸:** ë¨¼ì €, 'ê²€ìˆ˜ ëŒ€ìƒ í…œí”Œë¦¿'ì— ì–´ë–¤ ë‚´ìš©ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ê°ê´€ì ìœ¼ë¡œ ì„œìˆ í•˜ì„¸ìš”.
            b. **ê·œì • ì—°ê²°:** ë‹¤ìŒìœ¼ë¡œ, í™•ì¸ëœ ì‚¬ì‹¤ê³¼ ê°€ì¥ ê´€ë ¨ì„±ì´ ë†’ì€ 'ê´€ë ¨ ê·œì •' ë˜ëŠ” 'ìœ ì‚¬í•œ ê³¼ê±° ë°˜ë ¤ ì‚¬ë¡€'ë¥¼ 1~3ê°œ ì°¾ì•„ ì—°ê²°í•˜ì„¸ìš”.
            c. **ìµœì¢… ê²°ë¡ :** ë§ˆì§€ë§‰ìœ¼ë¡œ, ìœ„ ì‚¬ì‹¤ê³¼ ê·œì •ì„ ì¢…í•©í•˜ì—¬ ì™œ ì´ í…œí”Œë¦¿ì´ 'accepted' ë˜ëŠ” 'rejected'ì¸ì§€ ëª…í™•í•œ ê²°ë¡ ì„ ë‚´ë¦¬ì„¸ìš”.
        2. ìœ„ë°˜ ì‚¬í•­ì´ ì—†ë‹¤ë©´ 'status'ë¥¼ 'accepted'ë¡œ ì„¤ì •í•˜ê³ , 'revised_template'ì— ì›ë³¸ ì´ˆì•ˆì„ ê·¸ëŒ€ë¡œ ë„£ìœ¼ì„¸ìš”.
        3. ìœ„ë°˜ ì‚¬í•­ì´ ìˆë‹¤ë©´ 'status'ë¥¼ 'rejected'ë¡œ ì„¤ì •í•˜ê³ , 'suggestion'ì— êµ¬ì²´ì ì¸ ê°œì„  ë°©ì•ˆì„ ì œì‹œí•˜ì„¸ìš”.

        # ì¶œë ¥ í˜•ì‹ (JSON):
        {format_instructions}
        """
    )
    
    validation_chain = validation_prompt | llm | parser
    result = validation_chain.invoke({
        "draft": draft,
        "rules": rules_with_metadata,
        "rejections": rejections,
        "format_instructions": parser.get_format_instructions()
    })
    
    return result

def correct_template(state: dict) -> str:
    """í…œí”Œë¦¿ ìˆ˜ì •"""
    attempts = state.get('correction_attempts', 0)
    
    if attempts == 0:
        instruction = "3. ê´‘ê³ ì„± ë¬¸êµ¬ë¥¼ ì œê±°í•˜ê±°ë‚˜, ì •ë³´ì„± ë‚´ìš©ìœ¼ë¡œ ìˆœí™”í•˜ëŠ” ë“±, ì œì•ˆëœ ë°©í–¥ì— ë§ê²Œ í…œí”Œë¦¿ì„ ìˆ˜ì •í•˜ì„¸ìš”."
    elif attempts == 1:
        instruction = "3. **(2ì°¨ ìˆ˜ì •)** ì•„ì§ë„ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” 'ì¿ í°', 'í• ì¸', 'ì´ë²¤íŠ¸', 'íŠ¹ê°€'ì™€ ê°™ì€ ëª…ë°±í•œ ê´‘ê³ ì„± ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."
    else:
        instruction = """3. **(ìµœì¢… ìˆ˜ì •: ê´€ì  ì „í™˜)** ì—¬ì „íˆ ê´‘ê³ ì„±ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì´ê²ƒì´ ë§ˆì§€ë§‰ ì‹œë„ì…ë‹ˆë‹¤.
        - **ê´€ì  ì „í™˜:** ë©”ì‹œì§€ì˜ ì£¼ì²´ë¥¼ 'ìš°ë¦¬(ì‚¬ì—…ì)'ì—ì„œ 'ê³ ê°ë‹˜'ìœ¼ë¡œ ì™„ì „íˆ ë°”ê¾¸ì„¸ìš”.
        - **ëª©ì  ë³€ê²½:** 'íŒë§¤'ë‚˜ 'ë°©ë¬¸ ìœ ë„'ê°€ ì•„ë‹ˆë¼, 'ê³ ê°ë‹˜ì´ ê³¼ê±°ì— ë™ì˜í•œ ë‚´ìš©ì— ë”°ë¼ ê³ ê°ë‹˜ì˜ ê¶Œë¦¬(í˜œíƒ) ì •ë³´ë¥¼ ì•ˆë‚´'í•˜ëŠ” ê²ƒìœ¼ë¡œ ëª©ì ì„ ì¬ì •ì˜í•˜ì„¸ìš”."""
    
    correction_prompt_template = """ë‹¹ì‹ ì€ ì§€ì ëœ ë¬¸ì œì ì„ í•´ê²°í•˜ì—¬ ë” ë‚˜ì€ ëŒ€ì•ˆì„ ì œì‹œí•˜ëŠ” ì „ë¬¸ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
    ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì•„ë˜ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ **ìˆ˜ì •ëœ í…œí”Œë¦¿ ì´ˆì•ˆ í•˜ë‚˜ë§Œ**ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ˆì•ˆ ì™¸ì— ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ë¡œ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”.

    # ì›ë˜ ì‚¬ìš©ì ìš”ì²­: {original_request}
    # ì´ì „ì— ì œì•ˆí–ˆë˜ í…œí”Œë¦¿ (ë°˜ë ¤ë¨): {rejected_draft}
    # ë°˜ë ¤ ì‚¬ìœ  ë° ê°œì„  ì œì•ˆ: {rejection_reason}

    # ì§€ì‹œì‚¬í•­
    1. 'ë°˜ë ¤ ì‚¬ìœ  ë° ê°œì„  ì œì•ˆ'ì„ ì™„ë²½í•˜ê²Œ ì´í•´í•˜ê³ , ì§€ì ëœ ëª¨ë“  ë¬¸ì œì ì„ í•´ê²°í•˜ì„¸ìš”.
    2. 'ì›ë˜ ì‚¬ìš©ì ìš”ì²­'ì˜ í•µì‹¬ ì˜ë„ëŠ” ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
    {dynamic_instruction}

    # ìˆ˜ì •ëœ í…œí”Œë¦¿ ì´ˆì•ˆ (ì˜¤ì§ í…œí”Œë¦¿ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥):
    """
    
    correction_prompt = ChatPromptTemplate.from_template(correction_prompt_template)
    correction_prompt = correction_prompt.partial(dynamic_instruction=instruction)
    
    correction_chain = correction_prompt | llm | StrOutputParser()
    
    new_draft = correction_chain.invoke({
        "original_request": state['original_request'],
        "rejected_draft": state['template_draft'],
        "rejection_reason": state['validation_result']['reason'] + "\nê°œì„  ì œì•ˆ: " + state['validation_result']['suggestion']
    })
    
    return new_draft

@chatbot_bp.route('/health', methods=['GET'])
def health():
    return jsonify({'status': 'healthy'})