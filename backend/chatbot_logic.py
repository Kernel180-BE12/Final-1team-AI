import os
import json
import re
import traceback
from typing import TypedDict, List, Optional, Dict
import sys

# Pydantic ë° LangChain í˜¸í™˜ì„±ì„ ìœ„í•œ ì„í¬íŠ¸
from pydantic import BaseModel, Field, PrivateAttr

# LangChain ë° ê´€ë ¨ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
from langchain_community.document_loaders.base import BaseLoader
from langchain_community.vectorstores import Chroma
from langchain.retrievers import EnsembleRetriever, ContextualCompressionRetriever
from langchain_community.retrievers import BM25Retriever
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser, JsonOutputParser
from langchain_core.runnables import Runnable
from langchain_core.retrievers import BaseRetriever
from langchain_core.callbacks.manager import CallbackManagerForRetrieverRun

# FlashRank ì„í¬íŠ¸
try:
    from flashrank import Ranker, RerankRequest
    from langchain_core.documents.compressor import BaseDocumentCompressor
    from langchain_core.callbacks.base import Callbacks
except ImportError:
    print("FlashRank ë˜ëŠ” ê´€ë ¨ ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    BaseDocumentCompressor = object
    Ranker = None

# --- ì„¤ì • ë° ëª¨ë¸ ì •ì˜ ---
MAX_CORRECTION_ATTEMPTS = 3

# --- RA-HyDE (Retrieval-Augmented HyDE) êµ¬í˜„ í´ë˜ìŠ¤ ---
class ManualHydeRetriever(BaseRetriever):
    base_retriever: BaseRetriever
    llm: Runnable
    prompt: ChatPromptTemplate

    class Config:
        arbitrary_types_allowed = True

    def _get_relevant_documents(
            self, query: str, *, run_manager: CallbackManagerForRetrieverRun
    ) -> List[Document]:
        few_shot_docs = self.base_retriever.get_relevant_documents(
            query, callbacks=run_manager.get_child()
        )
        context = "\n\n---\n\n".join([doc.page_content for doc in few_shot_docs[:2]])
        generation_chain = self.prompt | self.llm | StrOutputParser()
        hypothetical_document = generation_chain.invoke(
            {"question": query, "context": context},
            config={"callbacks": run_manager.get_child()}
        )
        return self.base_retriever.get_relevant_documents(
            hypothetical_document, callbacks=run_manager.get_child()
        )


class CustomRuleLoader(BaseLoader):
    def __init__(self, file_path: str, encoding: str = 'utf-8'):
        self.file_path = file_path
        self.encoding = encoding

    def load(self) -> List[Document]:
        docs = []
        try:
            with open(self.file_path, 'r', encoding=self.encoding) as f:
                content = f.read()
        except FileNotFoundError:
            print(f"ğŸš¨ ê²½ê³ : '{self.file_path}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []

        rule_blocks = re.findall(r'\[ê·œì¹™ ì‹œì‘\](.*?)\[ê·œì¹™ ë\]', content, re.DOTALL)
        for block in rule_blocks:
            lines = block.strip().split('\n')
            metadata = {}
            page_content = ""
            is_content_section = False

            for line in lines:
                if line.lower().startswith('content:'):
                    is_content_section = True
                    page_content += line[len('content:'):].strip() + "\n"
                    continue
                if is_content_section:
                    page_content += line.strip() + "\n"
                else:
                    if ':' in line:
                        key, value = line.split(':', 1)
                        metadata[key.strip()] = value.strip()

            if page_content:
                docs.append(Document(page_content=page_content.strip(), metadata=metadata))

        return docs


class TemplateAnalysisResult(BaseModel):
    status: str = Field(description="í…œí”Œë¦¿ì˜ ìµœì¢… ìƒíƒœ (ì˜ˆ: 'accepted', 'rejected')")
    reason: str = Field(description="ìƒì„¸í•œ íŒë‹¨ ì´ìœ  (ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±)")
    evidence: Optional[str] = Field(None, description="íŒë‹¨ ê·¼ê±°ê°€ ëœ ê·œì¹™ì˜ rule_id (ì‰¼í‘œë¡œ êµ¬ë¶„)")
    suggestion: Optional[str] = Field(None, description="í…œí”Œë¦¿ ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì œì•ˆ (ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±)")
    revised_template: Optional[str] = Field(None, description="ê·œì •ì— ë§ê²Œ ìˆ˜ì •ëœ í…œí”Œë¦¿ ì˜ˆì‹œ")

class FlashRankRerank(BaseDocumentCompressor):
    _ranker: Ranker = PrivateAttr()
    top_n: int = 3

    def __init__(self, *args, **kwargs):
        super().__init__(*args, **kwargs)
        if Ranker:
            self._ranker = Ranker()

    class Config:
        arbitrary_types_allowed = True

    def compress_documents(self, documents: List[Document], query: str, callbacks: Callbacks | None = None) -> List[Document]:
        if not documents or not Ranker:
            return documents[:self.top_n]

        rerank_request = RerankRequest(
            query=query,
            passages=[{"id": i, "text": doc.page_content, "metadata": doc.metadata} for i, doc in enumerate(documents)]
        )
        reranked_results = self._ranker.rerank(rerank_request)

        final_docs = []
        for item in reranked_results[:self.top_n]:
            doc = documents[item['id']]
            doc.metadata["relevance_score"] = item['score']
            final_docs.append(doc)

        return final_docs

class Variable(BaseModel):
    name: str = Field(description="ì¶”ì¶œëœ ë³€ìˆ˜ì˜ í•œê¸€ ì´ë¦„ (ì˜ˆ: ë§¤ì¥ëª…, íì ì¼ì). `#{}`ì— ë“¤ì–´ê°ˆ ë¶€ë¶„ì…ë‹ˆë‹¤.")
    original_value: str = Field(description="ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ì¶”ì¶œëœ ì‹¤ì œ ê°’")
    description: str = Field(description="í•´ë‹¹ ë³€ìˆ˜ì— ëŒ€í•œ ê°„ë‹¨í•œ í•œê¸€ ì„¤ëª… (ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰½ë„ë¡)")

class ParameterizedResult(BaseModel):
    parameterized_template: str = Field(description="íŠ¹ì • ì •ë³´ê°€ #{ë³€ìˆ˜ëª…}ìœ¼ë¡œ ëŒ€ì²´ëœ ìµœì¢… í…œí”Œë¦¿")
    variables: List[Variable] = Field(description="ì¶”ì¶œëœ ë³€ìˆ˜ë“¤ì˜ ëª©ë¡")

# --- ì „ì—­ ë³€ìˆ˜ ë° í—¬í¼ í•¨ìˆ˜ ---
llm = None
retrievers = {}
approved_templates = []
rejected_templates = []

# ìŠ¤íƒ€ì¼ë³„ ì˜ˆì‹œ í…œí”Œë¦¿ ì •ì˜ (ì•„ì´ì½˜ ë§ˆì»¤ ì¶”ê°€)
STYLE_EXAMPLES = {
    "ê¸°ë³¸í˜•": [
        "íšŒì› ì•ˆë‚´ì‚¬í•­ ì „ë‹¬\nì•ˆë…•í•˜ì„¸ìš”, #{ìˆ˜ì‹ ì}ë‹˜!\n#{ë°œì‹  ìŠ¤í˜ì´ìŠ¤}ì˜ íšŒì›ì´ ë˜ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤.\n\nğŸ”” ì‹ ê·œ íšŒì› ì•ˆë‚´ ì‚¬í•­ ğŸ””\n#{ì•ˆë‚´ì‚¬í•­}\n\në²„íŠ¼ëª…",
    ],
    "ì´ë¯¸ì§€í˜•": [
        "[ICON=USER]\níšŒì› ë“±ê¸‰ ë³€ê²½\nì•ˆë…•í•˜ì„¸ìš”, #{ìˆ˜ì‹ ìëª…}ë‹˜.\n#{ë°œì‹  ìŠ¤í˜ì´ìŠ¤}ì…ë‹ˆë‹¤.\n\nê³ ê°ë‹˜ì˜ íšŒì› ë“±ê¸‰ì´ ë³€ê²½ë˜ì—ˆìŠµë‹ˆë‹¤.\n- ê¸°ì¡´ ë“±ê¸‰: #{ê¸°ì¡´ ë“±ê¸‰}\n- ë³€ê²½ ë“±ê¸‰: #{ë³€ê²½ ë“±ê¸‰}\n\nì•ìœ¼ë¡œë„ ë§ì€ ì´ìš© ë¶€íƒë“œë¦½ë‹ˆë‹¤.\në²„íŠ¼ëª…",
    ],
    "ì•„ì´í…œë¦¬ìŠ¤íŠ¸í˜•": [
        "[ICON=BARCODE]\nì°¸ê°€ì½”ë“œ ì•ˆë‚´\nì•ˆë…•í•˜ì„¸ìš”, #{ë°œì‹  ìŠ¤í˜ì´ìŠ¤}ì…ë‹ˆë‹¤.\n\nì˜ˆì •ëœ ì˜¨ë¼ì¸ êµìœ¡ì˜ ì°¸ê°€ì½”ë“œê°€ ì•„ë˜ì™€ ê°™ì´ ë°œì†¡ë˜ì—ˆìŠµë‹ˆë‹¤.\n- êµìœ¡ì¼ì: #{êµìœ¡ì¼ì}\n- êµìœ¡ì‹œê°„: #{êµìœ¡ì‹œê°„}\n- ì°¸ê°€ì½”ë“œ: #{ì°¸ê°€ì½”ë“œ}\n\nìì„¸í•œ ë¬¸ì˜ëŠ” #{ë¬¸ì˜ë²ˆí˜¸}ë¡œ ì—°ë½í•´ ì£¼ì„¸ìš”.\nê°ì‚¬í•©ë‹ˆë‹¤.\në²„íŠ¼ëª…",
    ]
}

def detect_template_style(template_content: str) -> str:
    """í…œí”Œë¦¿ ë‚´ìš©ì„ ë¶„ì„í•˜ì—¬ ìŠ¤íƒ€ì¼ì„ ìë™ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤."""
    if '[ICON=' in template_content:
        return 'ì´ë¯¸ì§€í˜•'
    elif 'â–¶' in template_content or ('- ' in template_content and ':' in template_content):
        return 'ì•„ì´í…œë¦¬ìŠ¤íŠ¸í˜•'
    else:
        return 'ê¸°ë³¸í˜•'

def load_line_by_line(file_path: str) -> List[str]:
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            items = [line.strip() for line in f if line.strip()]
        return items
    except FileNotFoundError:
        return []

def load_by_separator(file_path: str, separator: str = '---') -> List[str]:
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        items = [section.strip() for section in content.split(separator) if section.strip()]
        return items
    except FileNotFoundError:
        return []

def parameterize_template(template_string: str) -> Dict:
    parser = JsonOutputParser(pydantic_object=ParameterizedResult)
    prompt = ChatPromptTemplate.from_template(
        """ë‹¹ì‹ ì€ ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ë¥¼ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ í…ìŠ¤íŠ¸ì—ì„œ ê³ ìœ ëª…ì‚¬, ë‚ ì§œ, ì¥ì†Œ, ìˆ«ì ë“± êµ¬ì²´ì ì´ê³  ë°”ë€” ìˆ˜ ìˆëŠ” ì •ë³´ë“¤ì„ ì‹ë³„í•˜ì—¬, ì˜ë¯¸ ìˆëŠ” í•œê¸€ ë³€ìˆ˜ëª…ìœ¼ë¡œ ëŒ€ì²´í•´ì£¼ì„¸ìš”.
        
        # ì§€ì‹œì‚¬í•­
        1. í…ìŠ¤íŠ¸ì˜ í•µì‹¬ ì •ë³´(ëˆ„ê°€, ì–¸ì œ, ì–´ë””ì„œ, ë¬´ì—‡ì„, ì–´ë–»ê²Œ ë“±)ë¥¼ íŒŒì•…í•©ë‹ˆë‹¤.
        2. íŒŒì•…ëœ ì •ë³´ë¥¼ `#{{ë³€ìˆ˜ëª…}}` í˜•íƒœë¡œ ëŒ€ì²´í•˜ì—¬ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤. ë³€ìˆ˜ëª…ì€ ì‚¬ìš©ìê°€ ì´í•´í•˜ê¸° ì‰¬ìš´ í•œê¸€ë¡œ ì‘ì„±í•˜ì„¸ìš”.
        3. ì›ë³¸ ê°’ê³¼ ë³€ìˆ˜ëª…, ê·¸ë¦¬ê³  ê° ë³€ìˆ˜ì— ëŒ€í•œ ì„¤ëª…ì„ í¬í•¨í•˜ëŠ” ë³€ìˆ˜ ëª©ë¡ì„ ìƒì„±í•©ë‹ˆë‹¤.
        4. **ëª¨ë“  ì„¤ëª…ê³¼ ë³€ìˆ˜ëª…ì€ ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.**
        5. ìµœì¢… ê²°ê³¼ë¥¼ ì§€ì •ëœ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤. ê·¸ ì™¸ì˜ ì„¤ëª…ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

        # ì›ë³¸ í…ìŠ¤íŠ¸:
        {original_text}

        # ì¶œë ¥ í˜•ì‹ (JSON):
        {format_instructions}
        """
    )
    chain = prompt | llm | parser
    try:
        result = chain.invoke({
            "original_text": template_string,
            "format_instructions": parser.get_format_instructions(),
        })
        if not isinstance(result, dict):
            result = {"parameterized_template": template_string, "variables": []}
        if "parameterized_template" not in result:
            result["parameterized_template"] = template_string
        if "variables" not in result:
            result["variables"] = []
        return result
    except Exception as e:
        print(f"Error during parameterization: {e}")
        return {"parameterized_template": template_string, "variables": []}

def create_hybrid_retriever(vectorstore, docs, llm, embeddings, hyde_prompt):
    if not vectorstore:
        return None
    base_vector_retriever = vectorstore.as_retriever(search_kwargs={"k": 10})
    manual_hyde_retriever = ManualHydeRetriever(
        base_retriever=base_vector_retriever,
        llm=llm,
        prompt=hyde_prompt
    )
    if docs:
        keyword_retriever = BM25Retriever.from_documents(docs)
        keyword_retriever.k = 10
        ensemble_retriever = EnsembleRetriever(
            retrievers=[manual_hyde_retriever, keyword_retriever], weights=[0.6, 0.4]
        )
    else:
        ensemble_retriever = manual_hyde_retriever
    if Ranker:
        compressor = FlashRankRerank(top_n=5)
        return ContextualCompressionRetriever(base_compressor=compressor, base_retriever=ensemble_retriever)
    return ensemble_retriever

def initialize_system():
    global llm, retrievers, approved_templates, rejected_templates
    if llm is not None:
        return

    print("ì„œë²„ ì‹œì‘: ì‹œìŠ¤í…œ ì´ˆê¸°í™”ë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...")
    try:
        data_dir = 'data'
        vector_db_path = "vector_db"
        llm = ChatOpenAI(model="gpt-4o", temperature=0)
        embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
        approved_templates = load_line_by_line(os.path.join(data_dir, "approved_templates.txt"))
        rejected_templates = load_by_separator(os.path.join(data_dir, "rejected_templates.txt"))
        docs_compliance = CustomRuleLoader(os.path.join(data_dir, "compliance_rules.txt")).load()
        docs_generation = CustomRuleLoader(os.path.join(data_dir, "generation_rules.txt")).load()
        docs_whitelist = [Document(page_content=t) for t in approved_templates]
        docs_rejected = [Document(page_content=t) for t in rejected_templates]

        from chromadb.config import Settings
        client_settings = Settings(anonymized_telemetry=False)

        def create_db(name, docs):
            if docs:
                return Chroma.from_documents(
                    docs, embeddings, collection_name=name,
                    persist_directory=vector_db_path, client_settings=client_settings
                )
            return None

        db_compliance = create_db("compliance_rules", docs_compliance)
        db_generation = create_db("generation_rules", docs_generation)
        db_whitelist = create_db("whitelist_templates", docs_whitelist)
        db_rejected = create_db("rejected_templates", docs_rejected)

        hyde_prompt_base = """ë‹¹ì‹ ì€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ì˜ˆì‹œë¥¼ ì°¸ê³ í•˜ì—¬, ì‚¬ìš©ìì˜ ìš”ì²­ì— ê°€ì¥ ì´ìƒì ì¸ {doc_type}ì„(ë¥¼) í•œê¸€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
# ì˜ˆì‹œ: {context}
# ì‚¬ìš©ì ìš”ì²­: {question}
# ì´ìƒì ì¸ {doc_type}:"""

        base_prompt_template = ChatPromptTemplate.from_template(hyde_prompt_base)
        prompts = {
            'compliance': base_prompt_template.partial(doc_type="ê²€ìˆ˜ ê·œì • ë¬¸ì„œ"),
            'generation': base_prompt_template.partial(doc_type="í…œí”Œë¦¿ ìƒì„± ê°€ì´ë“œë¼ì¸"),
            'whitelist': base_prompt_template.partial(doc_type="ìŠ¹ì¸ í…œí”Œë¦¿ ì˜ˆì‹œ"),
            'rejected': base_prompt_template.partial(doc_type="ë°˜ë ¤ ì‚¬ë¡€")
        }

        dbs = {
            'compliance': (db_compliance, docs_compliance),
            'generation': (db_generation, docs_generation),
            'whitelist': (db_whitelist, docs_whitelist),
            'rejected': (db_rejected, docs_rejected)
        }

        for name, (db, docs) in dbs.items():
            if db:
                retrievers[name] = create_hybrid_retriever(db, docs, llm, embeddings, prompts[name])
                print(f"âœ… '{name}' ë¦¬íŠ¸ë¦¬ë²„ê°€ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
            else:
                print(f"ğŸš¨ ê²½ê³ : '{name}' ë¦¬íŠ¸ë¦¬ë²„ë¥¼ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        print("ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ.")
    except Exception as e:
        print(f"ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        raise e
    
def fill_template_with_request(template_structure: str, user_request: str) -> str:
    """
    ì£¼ì–´ì§„ í…œí”Œë¦¿ êµ¬ì¡°(í‹€)ì™€ ì‚¬ìš©ì ìš”ì²­ì„ ë°”íƒ•ìœ¼ë¡œ, LLMì„ ì‚¬ìš©í•˜ì—¬ ë³€ìˆ˜ë¥¼ ì±„ì›Œë„£ì€ ì™„ì„±ëœ í…œí”Œë¦¿ì„ ìƒì„±í•©ë‹ˆë‹¤.
    íŠ¹íˆ, #{ì œëª©}ê³¼ ê°™ì€ ìš”ì•½ ë³€ìˆ˜ëŠ” ì‚¬ìš©ì ìš”ì²­ì˜ í•µì‹¬ì„ íŒŒì•…í•˜ì—¬ ìƒì„±í•©ë‹ˆë‹¤.
    """
    prompt = ChatPromptTemplate.from_template(
        """ë‹¹ì‹ ì€ ì§€ì‹œë¥¼ ë§¤ìš° ì˜ ë”°ë¥´ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ì£¼ì–´ì§„ 'í…œí”Œë¦¿ êµ¬ì¡°'ì˜ ë³€ìˆ˜(`#{{...}}`)ë“¤ì„ 'ì‚¬ìš©ì ìš”ì²­'ì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” ì •ë³´ë¡œ ì±„ì›Œë„£ì–´, ì™„ì„±ëœ ì•Œë¦¼í†¡ ë©”ì‹œì§€ë¥¼ ë§Œë“œì„¸ìš”.

        # í…œí”Œë¦¿ êµ¬ì¡°:
        {template_structure}

        # ì‚¬ìš©ì ìš”ì²­:
        {user_request}

        # ì§€ì‹œì‚¬í•­:
        1. 'ì‚¬ìš©ì ìš”ì²­'ì˜ í•µì‹¬ ë‚´ìš©ì„ íŒŒì•…í•˜ì—¬ 'í…œí”Œë¦¿ êµ¬ì¡°'ì˜ ê° ë³€ìˆ˜ì— ê°€ì¥ ì ì ˆí•œ ê°’ì„ ì±„ì›Œë„£ìœ¼ì„¸ìš”.
        2. íŠ¹íˆ `#{{ì œëª©}}`ì´ë‚˜ `#{{ìš”ì•½}}`ê³¼ ê°™ì€ ë³€ìˆ˜ëŠ”, ì‚¬ìš©ì ìš”ì²­ì˜ í•µì‹¬ ë‚´ìš©ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì—¬ ì±„ì›Œë„£ì–´ì•¼ í•©ë‹ˆë‹¤. (ì˜ˆ: "ì£¼ê°„ íšŒì˜ ì°¸ì„ ì•ˆë‚´", "3ì›” ê¸‰ì—¬ëª…ì„¸ì„œ ë°œì†¡")
        3. ë§Œì•½ 'ì‚¬ìš©ì ìš”ì²­'ì—ì„œ íŠ¹ì • ë³€ìˆ˜ì— ëŒ€í•œ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ë‹¤ë©´, í•´ë‹¹ ë³€ìˆ˜ëŠ” `#{{ë³€ìˆ˜ëª…}}` í˜•íƒœë¡œ ê·¸ëŒ€ë¡œ ë‚¨ê²¨ë‘ì„¸ìš”.
        4. ìµœì¢… ê²°ê³¼ë¬¼ì€ ì˜¤ì§ ì™„ì„±ëœ í…œí”Œë¦¿ í…ìŠ¤íŠ¸ì—¬ì•¼ í•©ë‹ˆë‹¤. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ì£¼ì„ì€ ì ˆëŒ€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.

        # ì™„ì„±ëœ í…œí”Œë¦¿:
        """
    )
    chain = prompt | llm | StrOutputParser()
    filled_template = chain.invoke({
        "template_structure": template_structure,
        "user_request": user_request
    })
    return filled_template.strip()

def process_chat_message(message: str, state: dict) -> dict:
    try:
        current_step = state.get('step', 'initial')
        print(f"--- Processing Step: {current_step}, Message: {message} ---")

        while True:
            print(f"Executing step: {current_step}")
            next_step = None

            if current_step == 'initial':
                state['original_request'] = message
                next_step = 'recommend_templates'

            elif current_step == 'recommend_templates':
                if 'whitelist' not in retrievers or not retrievers['whitelist']:
                    next_step = 'ask_for_style'
                else:
                    similar_docs = retrievers['whitelist'].invoke(state['original_request'])
                    if not similar_docs:
                        next_step = 'ask_for_style'
                    else:
                        templates = [doc.page_content for doc in similar_docs[:3]]
                        template_options = [f"í…œí”Œë¦¿ {i+1}" for i in range(len(templates))]
                        
                        state['recommended_templates'] = templates
                        state['step'] = 'select_or_create'

                        templates_data = []
                        for template in templates:
                            detected_style = detect_template_style(template)
                            templates_data.append({
                                'content': template,
                                'style': detected_style
                            })

                        return {
                            'message': 'ìš”ì²­í•˜ì‹  ë‚´ìš©ê³¼ ìœ ì‚¬í•œ ê¸°ì¡´ í…œí”Œë¦¿ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤. ì•„ë˜ì—ì„œ ì„ íƒí•˜ì‹œê±°ë‚˜ "ì‹ ê·œ ìƒì„±"ì„ ì„ íƒí•´ì£¼ì„¸ìš”.\n(ë²„íŠ¼ í´ë¦­ ì‹œ ìš°ì¸¡ì— ë¯¸ë¦¬ë³´ê¸°ê°€ í‘œì‹œë©ë‹ˆë‹¤)',
                            'state': state,
                            'options': template_options + ['ì‹ ê·œ ìƒì„±'],
                            'templates_data': templates_data
                        }
            
            elif current_step == 'select_or_create':
                if message.startswith('í…œí”Œë¦¿'):
                    try:
                        template_idx = int(message.split(' ')[1]) - 1
                        if 0 <= template_idx < len(state.get('recommended_templates', [])):
                            state['selected_template_structure'] = state['recommended_templates'][template_idx]
                            next_step = 'fill_template'
                        else:
                            return {'message': 'ì˜ëª»ëœ í…œí”Œë¦¿ ë²ˆí˜¸ì…ë‹ˆë‹¤. ë‹¤ì‹œ ì„ íƒí•´ì£¼ì„¸ìš”.', 'state': state}
                    except (ValueError, IndexError):
                        next_step = 'ask_for_style'
                
                elif message == 'ì‹ ê·œ ìƒì„±':
                    next_step = 'ask_for_style'
                else:
                    return {'message': 'ì•Œ ìˆ˜ ì—†ëŠ” ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.', 'state': state}

            elif current_step == 'fill_template':
                print("ì‚¬ìš©ì ìš”ì²­ìœ¼ë¡œ í…œí”Œë¦¿ ì±„ìš°ëŠ” ì¤‘...")
                filled_draft = fill_template_with_request(
                    template_structure=state['selected_template_structure'],
                    user_request=state['original_request']
                )
                state['template_draft'] = filled_draft
                state['selected_style'] = detect_template_style(filled_draft)
                next_step = 'validation'

            elif current_step == 'ask_for_style':
                options = ['ê¸°ë³¸í˜•', 'ì´ë¯¸ì§€í˜•', 'ì•„ì´í…œë¦¬ìŠ¤íŠ¸í˜•']
                templates_data = []
                for style in options:
                    example_template = STYLE_EXAMPLES.get(style, [""])[0] 
                    templates_data.append({
                        'content': example_template,
                        'style': style
                    })
                state['step'] = 'process_style_selection'
                return {
                    'message': 'ì–´ë–¤ ìŠ¤íƒ€ì¼ì˜ í…œí”Œë¦¿ì„ ì›í•˜ì‹œë‚˜ìš”? ê° ìŠ¤íƒ€ì¼ì˜ ë¯¸ë¦¬ë³´ê¸°ë¥¼ í™•ì¸í•˜ê³  ì„ íƒí•´ì£¼ì„¸ìš”.',
                    'state': state,
                    'options': options,
                    'templates_data': templates_data
                }

            elif current_step == 'process_style_selection':
                if message in ['ê¸°ë³¸í˜•', 'ì´ë¯¸ì§€í˜•', 'ì•„ì´í…œë¦¬ìŠ¤íŠ¸í˜•']:
                    state['selected_style'] = message
                    next_step = 'generate_template'
                else:
                    state['step'] = 'ask_for_style'
                    return {'message': 'ì˜¬ë°”ë¥¸ ìŠ¤íƒ€ì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.', 'state': state}

            elif current_step == 'generate_template':
                print(f"í…œí”Œë¦¿ ìƒì„± ì¤‘... ìš”ì²­: {state['original_request']}, ìŠ¤íƒ€ì¼: {state['selected_style']}")
                template_draft = generate_template(state['original_request'], state['selected_style'])
                state['template_draft'] = template_draft
                next_step = 'validation'

            elif current_step == 'validation':
                print("í…œí”Œë¦¿ ê²€ì¦ ì¤‘...")
                validation_result = validate_template(state['template_draft'])
                state['validation_result'] = validation_result
                
                if validation_result.get('status') == 'accepted':
                    next_step = 'completed'
                else:
                    state['correction_attempts'] = state.get('correction_attempts', 0)
                    next_step = 'correction'

            elif current_step == 'correction':
                attempts = state.get('correction_attempts', 0)
                if attempts < MAX_CORRECTION_ATTEMPTS:
                    print(f"ìë™ ìˆ˜ì • ì‹œë„ ì¤‘... ({attempts + 1}/{MAX_CORRECTION_ATTEMPTS})")
                    corrected_template = correct_template(state)
                    state['template_draft'] = corrected_template
                    state['correction_attempts'] = attempts + 1
                    next_step = 'validation'
                else:
                    state['step'] = 'manual_correction'
                    return {
                        'message': f'AI ìë™ ìˆ˜ì •ì´ {MAX_CORRECTION_ATTEMPTS}íšŒ ëª¨ë‘ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n\në§ˆì§€ë§‰ ì‹œë„ ê²°ê³¼:\n{state["validation_result"]["reason"]}\n\nì§ì ‘ ìˆ˜ì •í•´ì£¼ì‹œê±°ë‚˜ "í¬ê¸°í•˜ê¸°"ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.\n\ní˜„ì¬ í…œí”Œë¦¿:\n{state["template_draft"]}',
                        'state': state,
                        'options': ['í¬ê¸°í•˜ê¸°'],
                        'template_data': {
                            'content': state["template_draft"],
                            'style': state.get("selected_style", "ê¸°ë³¸í˜•")
                        }
                    }

            elif current_step == 'manual_correction':
                if message == 'í¬ê¸°í•˜ê¸°':
                    return {
                        'message': 'í…œí”Œë¦¿ ìƒì„±ì„ í¬ê¸°í–ˆìŠµë‹ˆë‹¤. ìƒˆë¡œìš´ ìš”ì²­ì„ í•´ì£¼ì„¸ìš”.',
                        'state': {'step': 'initial'}
                    }
                else:
                    state['template_draft'] = message
                    next_step = 'validation'

            elif current_step == 'completed':
                final_template = state.get("template_draft", "")
                final_style = state.get("selected_style", "ê¸°ë³¸í˜•")
                parameterized_result = parameterize_template(final_template)
                
                return {
                    'message': 'âœ… í…œí”Œë¦¿ì´ ì„±ê³µì ìœ¼ë¡œ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤!',
                    'state': {'step': 'initial'},
                    'template': final_template,
                    'editable_variables': parameterized_result,
                    'template_data': {
                        'content': parameterized_result.get('parameterized_template', final_template),
                        'style': final_style
                    }
                }

            else:
                return {'message': 'ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.', 'state': {'step': 'initial'}}

            if next_step:
                current_step = next_step
            else:
                break
        
        return {'message': 'ì²˜ë¦¬ê°€ ì™„ë£Œë˜ì—ˆì§€ë§Œ ë°˜í™˜í•  ë©”ì‹œì§€ê°€ ì—†ìŠµë‹ˆë‹¤.', 'state': state}

    except Exception as e:
        print(f"Error in process_chat_message: {e}")
        traceback.print_exc()
        return {'message': f'ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}', 'state': {'step': 'initial'}}

def generate_template(request: str, style: str = "ê¸°ë³¸í˜•") -> str:
    try:
        rules = "ì‚¬ìš©ìì˜ ìš”ì²­ì— ë§ì¶° ì •ë³´ì„± í…œí”Œë¦¿ì„ ìƒì„±í•˜ì„¸ìš”."
        if 'generation' in retrievers and retrievers['generation']:
            docs = retrievers['generation'].invoke(request)
            rules = "\n".join([doc.page_content for doc in docs])

        prompt = ChatPromptTemplate.from_template(
            """ë‹¹ì‹ ì€ ì•Œë¦¼í†¡ í…œí”Œë¦¿ ìƒì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ìš”ì²­ì— ë”°ë¼ ì ì ˆí•œ ì•Œë¦¼í†¡ í…œí”Œë¦¿ì„ ìƒì„±í•´ì£¼ì„¸ìš”.
            # ì‚¬ìš©ì ìš”ì²­: {request}
            # ì„ íƒëœ ìŠ¤íƒ€ì¼: {style}
            # ìƒì„± ê·œì¹™: {rules}
            # ì§€ì‹œì‚¬í•­: í…œí”Œë¦¿ì€ ì œëª©, ë³¸ë¬¸, ë²„íŠ¼ í…ìŠ¤íŠ¸ë¡œ êµ¬ì„±ë˜ì–´ì•¼ í•˜ë©°, ê° ì¤„ì€ ê°œí–‰ìœ¼ë¡œ êµ¬ë¶„ë©ë‹ˆë‹¤. í…œí”Œë¦¿ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""
        )
        chain = prompt | llm | StrOutputParser()
        return chain.invoke({"request": request, "style": style, "rules": rules}).strip()
    except Exception as e:
        print(f"Error in generate_template: {e}")
        return "í…œí”Œë¦¿ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.\në‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.\ní™•ì¸"

def validate_template(draft: str) -> dict:
    try:
        rules, rejections = "ê´‘ê³ ì„± ë¬¸êµ¬ ê¸ˆì§€", "ê´‘ê³ ì„± ë¬¸êµ¬ í¬í•¨ëœ ì‚¬ë¡€"
        if 'compliance' in retrievers and retrievers['compliance']:
            docs = retrievers['compliance'].invoke(draft)
            rules = "\n".join([f"[ID: {doc.metadata.get('rule_id', 'N/A')}] {doc.page_content}" for doc in docs])
        if 'rejected' in retrievers and retrievers['rejected']:
            docs = retrievers['rejected'].invoke(draft)
            rejections = "\n".join([doc.page_content for doc in docs])

        parser = JsonOutputParser(pydantic_object=TemplateAnalysisResult)
        prompt = ChatPromptTemplate.from_template(
            """ë‹¹ì‹ ì€ ì•Œë¦¼í†¡ í…œí”Œë¦¿ì˜ ê·œì • ì¤€ìˆ˜ ì—¬ë¶€ë¥¼ íŒë‹¨í•˜ëŠ” í•œêµ­ì–´ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
            í…œí”Œë¦¿ ì´ˆì•ˆì„ ê²€í† í•˜ê³ , ê·œì • ìœ„ë°˜ ì—¬ë¶€ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

            # ì¤‘ìš” ì§€ì‹œì‚¬í•­:
            - ìµœì¢… ë¶„ì„ ê²°ê³¼(reason, suggestion ë“±)ëŠ” **ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±**í•´ì•¼ í•©ë‹ˆë‹¤. ì ˆëŒ€ë¡œ ì˜ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.
            - `status`ëŠ” 'accepted'(ìŠ¹ì¸) ë˜ëŠ” 'rejected'(ë°˜ë ¤) ì¤‘ í•˜ë‚˜ì—¬ì•¼ í•©ë‹ˆë‹¤.

            # ê²€í† í•  í…œí”Œë¦¿ ì´ˆì•ˆ:
            {draft}

            # ì¤€ìˆ˜í•´ì•¼ í•  ê·œì¹™ë“¤:
            {rules}

            # ê³¼ê±° ë°˜ë ¤ëœ í…œí”Œë¦¿ ì‚¬ë¡€ë“¤:
            {rejections}

            # ì¶œë ¥ í˜•ì‹ (JSON):
            {format_instructions}"""
        )
        chain = prompt | llm | parser
        return chain.invoke({
            "draft": draft, "rules": rules, "rejections": rejections,
            "format_instructions": parser.get_format_instructions()
        })
    except Exception as e:
        print(f"Error in validate_template: {e}")
        return {"status": "accepted", "reason": "ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ. ìë™ ìŠ¹ì¸ ì²˜ë¦¬ë©ë‹ˆë‹¤.", "suggestion": None, "revised_template": draft}

def correct_template(state: dict) -> str:
    try:
        attempts = state.get('correction_attempts', 0)
        if attempts <= 1:
            instruction = "3. ê´‘ê³ ì„± ë¬¸êµ¬ë¥¼ ì œê±°í•˜ê±°ë‚˜, ì •ë³´ì„± ë‚´ìš©ìœ¼ë¡œ ìˆœí™”í•˜ëŠ” ë“±, ì œì•ˆëœ ë°©í–¥ì— ë§ê²Œ í…œí”Œë¦¿ì„ ìˆ˜ì •í•˜ì„¸ìš”."
        elif attempts == 2:
            instruction = "3. **(2ì°¨ ìˆ˜ì •)** ì•„ì§ë„ ë¬¸ì œê°€ ìˆìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” 'ì¿ í°', 'í• ì¸', 'ì´ë²¤íŠ¸', 'íŠ¹ê°€'ì™€ ê°™ì€ ëª…ë°±í•œ ê´‘ê³ ì„± ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ê³ , ì •ë³´ ì „ë‹¬ì—ë§Œ ì§‘ì¤‘í•˜ì„¸ìš”."
        else:
            instruction = """3. **(ìµœì¢… ìˆ˜ì •: ê´€ì  ì „í™˜)** ì—¬ì „íˆ ê´‘ê³ ì„±ìœ¼ë¡œ ë³´ì…ë‹ˆë‹¤. ì´ê²ƒì´ ë§ˆì§€ë§‰ ì‹œë„ì…ë‹ˆë‹¤.
            - **ê´€ì  ì „í™˜:** ë©”ì‹œì§€ì˜ ì£¼ì²´ë¥¼ 'ìš°ë¦¬(ì‚¬ì—…ì)'ì—ì„œ 'ê³ ê°ë‹˜'ìœ¼ë¡œ ì™„ì „íˆ ë°”ê¾¸ì„¸ìš”.
            - **ëª©ì  ë³€ê²½:** 'íŒë§¤'ë‚˜ 'ë°©ë¬¸ ìœ ë„'ê°€ ì•„ë‹ˆë¼, 'ê³ ê°ë‹˜ì´ ê³¼ê±°ì— ë™ì˜í•œ ë‚´ìš©ì— ë”°ë¼ ê³ ê°ë‹˜ì˜ ê¶Œë¦¬(í˜œíƒ) ì •ë³´ë¥¼ ì•ˆë‚´'í•˜ëŠ” ê²ƒìœ¼ë¡œ ëª©ì ì„ ì¬ì •ì˜í•˜ì„¸ìš”."""

        correction_prompt_template = """ë‹¹ì‹ ì€ ì§€ì ëœ ë¬¸ì œì ì„ í•´ê²°í•˜ì—¬ ë” ë‚˜ì€ ëŒ€ì•ˆì„ ì œì‹œí•˜ëŠ” ì „ë¬¸ ì¹´í”¼ë¼ì´í„°ì…ë‹ˆë‹¤.
        ë‹¹ì‹ ì˜ ìœ ì¼í•œ ì„ë¬´ëŠ” ì•„ë˜ ì§€ì‹œì‚¬í•­ì— ë”°ë¼ **ìˆ˜ì •ëœ í…œí”Œë¦¿ ì´ˆì•ˆ í•˜ë‚˜ë§Œ**ì„ ìƒì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤. ì´ˆì•ˆ ì™¸ì— ë‹¤ë¥¸ ì„¤ëª…ì€ ì ˆëŒ€ë¡œ ë§ë¶™ì´ì§€ ë§ˆì„¸ìš”.
        
        # ì›ë˜ ì‚¬ìš©ì ìš”ì²­: {original_request}
        # ì´ì „ì— ì œì•ˆí–ˆë˜ í…œí”Œë¦¿ (ë°˜ë ¤ë¨): {rejected_draft}
        # ë°˜ë ¤ ì‚¬ìœ  ë° ê°œì„  ì œì•ˆ: {rejection_reason}
        
        # ì§€ì‹œì‚¬í•­
        1. 'ë°˜ë ¤ ì‚¬ìœ  ë° ê°œì„  ì œì•ˆ'ì„ ì™„ë²½í•˜ê²Œ ì´í•´í•˜ê³ , ì§€ì ëœ ëª¨ë“  ë¬¸ì œì ì„ í•´ê²°í•˜ì„¸ìš”.
        2. 'ì›ë˜ ì‚¬ìš©ì ìš”ì²­'ì˜ í•µì‹¬ ì˜ë„ëŠ” ìœ ì§€í•´ì•¼ í•©ë‹ˆë‹¤.
        {dynamic_instruction}
        
        # ìˆ˜ì •ëœ í…œí”Œë¦¿ ì´ˆì•ˆ (ì˜¤ì§ í…œí”Œë¦¿ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥):
        """
        correction_prompt = ChatPromptTemplate.from_template(correction_prompt_template)
        correction_prompt = correction_prompt.partial(dynamic_instruction=instruction)
        correction_chain = correction_prompt | llm | StrOutputParser()

        rejection_reason = state['validation_result']['reason']
        if state['validation_result'].get('suggestion'):
            rejection_reason += "\nê°œì„  ì œì•ˆ: " + state['validation_result']['suggestion']

        new_draft = correction_chain.invoke({
            "original_request": state['original_request'],
            "rejected_draft": state['template_draft'],
            "rejection_reason": rejection_reason
        })
        return new_draft.strip()
    except Exception as e:
        print(f"Error in correct_template: {e}")
        return state.get('template_draft', 'ìˆ˜ì • ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.')
